{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "# coding: utf-8\n",
    "\n",
    "import sys\n",
    "import requests\n",
    "from datetime import date, datetime, timedelta\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "if sys.version_info[0] == 2:\n",
    "    import urllib2 as ul # Python2\n",
    "else:\n",
    "    import urllib.request as ul # Python3\n",
    "import json\n",
    "\n",
    "\n",
    "def FacebookPageData(page_id, access_token):\n",
    "    \n",
    "    # construct the URL string\n",
    "    base = 'https://graph.facebook.com/v2.8'\n",
    "    node = '/' + page_id\n",
    "    parameters = '/?access_token=%s&fields=name,talking_about_count,fan_count' % access_token\n",
    "    url = base + node + parameters\n",
    "    \n",
    "    # retrieve data\n",
    "    response = ul.urlopen(url)\n",
    "    data = json.loads(response.read().decode('utf-8'))\n",
    "    \n",
    "    print('Facebook page :', data['name'])\n",
    "    return [int(data[metric]) for metric in ['fan_count', 'talking_about_count']]\n",
    "\n",
    "def YoutubePageData(page_id, access_token):\n",
    "    base = 'https://www.googleapis.com/youtube/v3/channels'\n",
    "    parameters = '?part=statistics&id=' + page_id + '&key=' + access_token\n",
    "    url = base + parameters\n",
    "    \n",
    "    # retrieve data\n",
    "    response = ul.urlopen(url)\n",
    "    data = json.loads(response.read().decode('utf-8'))\n",
    "    statistics = data['items'][0]['statistics']\n",
    "\n",
    "    return [int(statistics[metric]) for metric in ['subscriberCount', 'viewCount', 'videoCount']]\n",
    "\n",
    "def YoutubeVideosData(page_id, access_token):\n",
    "    base = 'https://www.googleapis.com/youtube/v3/search'\n",
    "    parameters = '?order=date&part=snippet&channelId=' + page_id + '&maxResults=10&key=' + access_token\n",
    "    url = base + parameters\n",
    "    \n",
    "    # retrieve list of the most recently published videos on the channel (10 or less)\n",
    "    response = ul.urlopen(url)\n",
    "    data = json.loads(response.read().decode('utf-8'))\n",
    "    videoIds = [e['id']['videoId'] for e in data['items'] if 'videoId' in e['id']]\n",
    "    \n",
    "    base = 'https://www.googleapis.com/youtube/v3/videos'\n",
    "    parameters = '?part=statistics&id=' + ','.join(videoIds) + '&key=' + access_token\n",
    "    url = base + parameters\n",
    "    \n",
    "    response = ul.urlopen(url)\n",
    "    data = json.loads(response.read().decode('utf-8'))\n",
    "    keys = data['items'][0]['statistics'].keys() # list of metrics\n",
    "    n = len(data['items'])\n",
    "    \n",
    "    # Construction du dictionnaire des valeurs moyennes pour chaque clé sur les vidéos analysées\n",
    "    videoStats = {key: int(round(sum([int(e['statistics'][key]) for e in data['items']]) / n)) for key in keys}\n",
    "    \n",
    "    print('Getting average metrics for the latest', n, 'videos of the channel')\n",
    "\n",
    "    return [videoStats[metric] for metric in ['viewCount', 'likeCount', 'dislikeCount']]\n",
    "\n",
    "def get_metrics():\n",
    "    df = pd.DataFrame()\n",
    "    print('Maj du', today)\n",
    "\n",
    "    for candidate in accounts:\n",
    "        print('-' * 20)\n",
    "        print(candidate)\n",
    "        print('-' * 20)\n",
    "\n",
    "        stats = {}\n",
    "        try: # Twitter : [tweets, followers]\n",
    "            print('Analyzing Twitter account', accounts[candidate][2])\n",
    "            soup = BeautifulSoup(requests.get('https://twitter.com/' + accounts[candidate][2] + '?lang=en').text, 'lxml')\n",
    "            stats_tw = [int(tag.attrs['title'].replace(',', '').split(' ')[0])\n",
    "                        for tag in soup.find_all(class_='ProfileNav-stat', limit=3) if 'title' in tag.attrs]\n",
    "        except:\n",
    "            stats_tw = ['-', '-', '-']\n",
    "            print('Profil Twitter : une erreur est survenue...')\n",
    "\n",
    "        _, _, stats['0_tw_followers'] = stats_tw\n",
    "\n",
    "        if accounts[candidate][0] is not None:\n",
    "            print('Scanning Youtube Channel')\n",
    "            try: # Youtube [abonnés, total vues, nombre de vidéos]\n",
    "                stats_yt = YoutubePageData(accounts[candidate][0], google_key)\n",
    "            except:\n",
    "                stats_yt = ['-', '-', '-']\n",
    "                print('Page Youtube : une erreur est survenue...')\n",
    "            try: # Youtube [moyenne vues 10 vidéos, moyenne likes 10 vidéos, moyenne dislikes 10 vidéos]\n",
    "                stats_yt2 = YoutubeVideosData(accounts[candidate][0], google_key)\n",
    "            except:\n",
    "                stats_yt2 = ['-', '-', '-']\n",
    "                print('Vidéos Youtube : une erreur est survenue...')\n",
    "        else:\n",
    "            print('No Youtube Channel')\n",
    "            stats_yt, stats_yt2 = ['-', '-', '-'], ['-', '-', '-']\n",
    "\n",
    "        stats['2_yt_subscribers'], _, _ = stats_yt\n",
    "        _, stats['3_yt_like_count'], stats['4_yt_dislike_count'] = stats_yt2\n",
    "\n",
    "        try:\n",
    "            pass\n",
    "            #stats['4_yt_reaction_rate'] = round((float(stats_yt2[1] + stats_yt2[2]) / stats_yt2[0]) * 100, 1)\n",
    "            #stats['5_yt_satisfaction_rate'] = round((float(stats_yt2[1]) / (stats_yt2[2] + stats_yt2[1])) * 100, 1)\n",
    "        except:\n",
    "            pass\n",
    "            #stats['4_yt_reaction_rate'] = '-'\n",
    "            #stats['5_yt_satisfaction_rate'] = '-'\n",
    "\n",
    "        try: # Facebook : [likes, people talking about this]\n",
    "            stats_fb = FacebookPageData(accounts[candidate][1], access_token)\n",
    "        except:\n",
    "            stats_fb = ['-', '-']\n",
    "            print('Page Facebook : une erreur est survenue...')\n",
    "\n",
    "        stats['6_fb_likes'], stats['7_fb_talking_about'] = stats_fb\n",
    "\n",
    "        print()\n",
    "        print(stats)\n",
    "\n",
    "        # ajout de la ligne du candidat dans le dataframe\n",
    "        rec = pd.DataFrame([stats.values()], columns=stats.keys(), index=[candidate])\n",
    "        df = df.append(rec, verify_integrity=False)\n",
    "\n",
    "    # ajout de la colonne des mentions twitter sur 3 jours\n",
    "    #tweet_data = pd.read_json('/var/www/html/decompte/popcontest.json', orient='column')\n",
    "    tweet_data = pd.read_json('popcontest.json', orient='column')\n",
    "    names, counts = [e['name'] for e in tweet_data['children']], [e['size'] for e in tweet_data['children']]\n",
    "    tweet_df = pd.DataFrame(counts, columns=['1_tw_mentions'], index=names)\n",
    "    tweet_df.fillna(value='-', inplace=True)\n",
    "\n",
    "    df = pd.concat([df, tweet_df], axis=1, join_axes=[df.index])\n",
    "    return df\n",
    "\n",
    "def save_metrics(df, timestamp):\n",
    "    # sauvegarde des colonnes du dataframe dans les différents .json\n",
    "    for metric in df:\n",
    "        try:\n",
    "            current_df = pd.read_json(path + metric + '.json', orient='split')\n",
    "            \n",
    "            if timestamp in current_df:\n",
    "                print('Fichier json deja a jour pour', metric)\n",
    "                continue\n",
    "                \n",
    "            current_df = pd.concat([current_df, df[metric]], axis=1)\n",
    "            \n",
    "        except ValueError: # si le fichier n'existe pas\n",
    "            current_df = pd.DataFrame(df[metric], columns=[metric], index=[df.index])\n",
    "\n",
    "        current_df.rename(columns={metric:timestamp}, inplace=True)\n",
    "        current_df.fillna(value='-', inplace=True)\n",
    "        current_df.to_json(path + metric + '.json', orient='split')\n",
    "        print('Data saved as ' + path + metric + '.json')\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# {Candidat : [Chaine Youtube, Compte Facebook, Compte Twitter]}\n",
    "accounts = {#'Alliot-Marie': [None, 'MAlliotMarie', 'MAlliotMarie'],\n",
    "           #'Arthaud': ['UCZsh-MrJftAOP_-ZgRgLScw', 'nathaliearthaud', 'n_arthaud'],\n",
    "           #'Bayrou': [None, 'bayrou', 'bayrou'],\n",
    "           #'Cheminade': ['UCCPw8MX-JcsiTzItY-qq1Fg', 'Jcheminade', 'Jcheminade'],\n",
    "           #'Dupont-Aignan': ['UCfA5DnCDX3Ixy5QOAMGtBlA', 'nicolasdupontaignan', 'dupontaignan'],\n",
    "           'Fillon': ['UCp1R4BFJrKw34PfUc3GDLkw', 'FrancoisFillon', 'francoisfillon'],\n",
    "           'Hamon': ['UCcMryUp6ME3BvP2alkS1dKg', 'hamonbenoit', 'benoithamon'],\n",
    "           #'Jadot': ['UCsUMhb2ygeTSS2mXLTIDHMQ', 'yannick.jadot', 'yjadot'],\n",
    "           'Le Pen': ['UCU3z3px1_RCqYBwrs8LJVWg', 'MarineLePen', 'MLP_officiel'],\n",
    "           'Macron': ['UCJw8np695wqWOaKVhFjkRyg', 'EmmanuelMacron', 'emmanuelmacron'],\n",
    "           u'Mélenchon': ['UCk-_PEY3iC6DIGJKuoEe9bw', 'JLMelenchon', 'JLMelenchon'],\n",
    "           #'Poutou': [None, 'poutou.philippe', 'PhilippePoutou']\n",
    "}\n",
    "\n",
    "app_id = \"615202351999343\"\n",
    "app_secret = \"ea787efd843d1de746817ec6e9bf7e94\"\n",
    "access_token = app_id + \"|\" + app_secret\n",
    "google_key = 'AIzaSyBkRrj_kFDUv-T76CJaI3Pd-g3v7UY4GMA'\n",
    "\n",
    "today = (datetime.utcnow() + timedelta(hours=1)).date()\n",
    "fname = str(today) + '.json'\n",
    "path = 'metric_data/' # save path\n",
    "#path = '/var/www/html/duel/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maj du 2017-03-15\n",
      "--------------------\n",
      "Macron\n",
      "--------------------\n",
      "Analyzing Twitter account emmanuelmacron\n",
      "Scanning Youtube Channel\n",
      "Getting average metrics for the latest 10 videos of the channel\n",
      "Facebook page : Emmanuel Macron\n",
      "\n",
      "{'3_yt_like_count': 411, '0_tw_followers': 562765, '6_fb_likes': 211361, '2_yt_subscribers': 10927, '7_fb_talking_about': 59431, '4_yt_dislike_count': 699}\n",
      "--------------------\n",
      "Le Pen\n",
      "--------------------\n",
      "Analyzing Twitter account MLP_officiel\n",
      "Scanning Youtube Channel\n",
      "Getting average metrics for the latest 10 videos of the channel\n",
      "Facebook page : Marine Le Pen\n",
      "\n",
      "{'3_yt_like_count': 263, '0_tw_followers': 1326503, '6_fb_likes': 1251073, '2_yt_subscribers': 15850, '7_fb_talking_about': 150244, '4_yt_dislike_count': 17}\n",
      "--------------------\n",
      "Fillon\n",
      "--------------------\n",
      "Analyzing Twitter account francoisfillon\n",
      "Scanning Youtube Channel\n",
      "Getting average metrics for the latest 10 videos of the channel\n",
      "Facebook page : François Fillon\n",
      "\n",
      "{'3_yt_like_count': 154, '0_tw_followers': 455936, '6_fb_likes': 306812, '2_yt_subscribers': 4607, '7_fb_talking_about': 68269, '4_yt_dislike_count': 42}\n",
      "--------------------\n",
      "Mélenchon\n",
      "--------------------\n",
      "Analyzing Twitter account JLMelenchon\n",
      "Scanning Youtube Channel\n",
      "Getting average metrics for the latest 10 videos of the channel\n",
      "Facebook page : Jean-Luc Mélenchon\n",
      "\n",
      "{'3_yt_like_count': 5370, '0_tw_followers': 994212, '6_fb_likes': 683467, '2_yt_subscribers': 233165, '7_fb_talking_about': 145153, '4_yt_dislike_count': 58}\n",
      "--------------------\n",
      "Hamon\n",
      "--------------------\n",
      "Analyzing Twitter account benoithamon\n",
      "Scanning Youtube Channel\n",
      "Getting average metrics for the latest 10 videos of the channel\n",
      "Facebook page : Benoît Hamon\n",
      "\n",
      "{'3_yt_like_count': 46, '0_tw_followers': 343673, '6_fb_likes': 140120, '2_yt_subscribers': 5620, '7_fb_talking_about': 41711, '4_yt_dislike_count': 11}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "save_metrics() missing 1 required positional argument: 'timestamp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-75c1a83a1deb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msave_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: save_metrics() missing 1 required positional argument: 'timestamp'"
     ]
    }
   ],
   "source": [
    "save_metrics(get_metrics(), today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2017-02-14 00:00:00</th>\n",
       "      <th>2017-02-15 00:00:00</th>\n",
       "      <th>2017-02-16 00:00:00</th>\n",
       "      <th>2017-02-17 00:00:00</th>\n",
       "      <th>2017-02-18 00:00:00</th>\n",
       "      <th>2017-02-19 00:00:00</th>\n",
       "      <th>2017-02-20 00:00:00</th>\n",
       "      <th>2017-02-21 00:00:00</th>\n",
       "      <th>2017-02-22 00:00:00</th>\n",
       "      <th>2017-02-23 00:00:00</th>\n",
       "      <th>...</th>\n",
       "      <th>2017-03-04 00:00:00</th>\n",
       "      <th>2017-03-05 00:00:00</th>\n",
       "      <th>2017-03-06 00:00:00</th>\n",
       "      <th>2017-03-07 00:00:00</th>\n",
       "      <th>2017-03-08 00:00:00</th>\n",
       "      <th>2017-03-09 00:00:00</th>\n",
       "      <th>2017-03-10 00:00:00</th>\n",
       "      <th>2017-03-11 00:00:00</th>\n",
       "      <th>2017-03-12 00:00:00</th>\n",
       "      <th>2017-03-13 00:00:00</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fillon</th>\n",
       "      <td>423181</td>\n",
       "      <td>424011</td>\n",
       "      <td>425149</td>\n",
       "      <td>426014</td>\n",
       "      <td>426789</td>\n",
       "      <td>427675</td>\n",
       "      <td>428638</td>\n",
       "      <td>429347</td>\n",
       "      <td>430143</td>\n",
       "      <td>430835</td>\n",
       "      <td>...</td>\n",
       "      <td>441924</td>\n",
       "      <td>445218</td>\n",
       "      <td>447365</td>\n",
       "      <td>448673</td>\n",
       "      <td>449698</td>\n",
       "      <td>450722</td>\n",
       "      <td>451641</td>\n",
       "      <td>452544</td>\n",
       "      <td>453580</td>\n",
       "      <td>454327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hamon</th>\n",
       "      <td>326739</td>\n",
       "      <td>327730</td>\n",
       "      <td>328988</td>\n",
       "      <td>329775</td>\n",
       "      <td>330478</td>\n",
       "      <td>331323</td>\n",
       "      <td>331974</td>\n",
       "      <td>332387</td>\n",
       "      <td>332865</td>\n",
       "      <td>333374</td>\n",
       "      <td>...</td>\n",
       "      <td>337695</td>\n",
       "      <td>338944</td>\n",
       "      <td>339670</td>\n",
       "      <td>340218</td>\n",
       "      <td>340815</td>\n",
       "      <td>341421</td>\n",
       "      <td>342218</td>\n",
       "      <td>342576</td>\n",
       "      <td>342768</td>\n",
       "      <td>342946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Le Pen</th>\n",
       "      <td>1272977</td>\n",
       "      <td>1274053</td>\n",
       "      <td>1275497</td>\n",
       "      <td>1276784</td>\n",
       "      <td>1278058</td>\n",
       "      <td>1279544</td>\n",
       "      <td>1281410</td>\n",
       "      <td>1284466</td>\n",
       "      <td>1287438</td>\n",
       "      <td>1289158</td>\n",
       "      <td>...</td>\n",
       "      <td>1307868</td>\n",
       "      <td>1309959</td>\n",
       "      <td>1312222</td>\n",
       "      <td>1313884</td>\n",
       "      <td>1315306</td>\n",
       "      <td>1316938</td>\n",
       "      <td>1318486</td>\n",
       "      <td>1319819</td>\n",
       "      <td>1321599</td>\n",
       "      <td>1323344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Macron</th>\n",
       "      <td>57998</td>\n",
       "      <td>496473</td>\n",
       "      <td>499164</td>\n",
       "      <td>501489</td>\n",
       "      <td>503556</td>\n",
       "      <td>505678</td>\n",
       "      <td>508232</td>\n",
       "      <td>510271</td>\n",
       "      <td>513332</td>\n",
       "      <td>515402</td>\n",
       "      <td>...</td>\n",
       "      <td>536933</td>\n",
       "      <td>539827</td>\n",
       "      <td>542253</td>\n",
       "      <td>544300</td>\n",
       "      <td>546901</td>\n",
       "      <td>549529</td>\n",
       "      <td>551699</td>\n",
       "      <td>553740</td>\n",
       "      <td>556027</td>\n",
       "      <td>558547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MÃ©lenchon</th>\n",
       "      <td>964205</td>\n",
       "      <td>965153</td>\n",
       "      <td>966236</td>\n",
       "      <td>967289</td>\n",
       "      <td>968269</td>\n",
       "      <td>969236</td>\n",
       "      <td>970551</td>\n",
       "      <td>971523</td>\n",
       "      <td>972501</td>\n",
       "      <td>973566</td>\n",
       "      <td>...</td>\n",
       "      <td>982680</td>\n",
       "      <td>984215</td>\n",
       "      <td>985415</td>\n",
       "      <td>986502</td>\n",
       "      <td>987424</td>\n",
       "      <td>988388</td>\n",
       "      <td>989204</td>\n",
       "      <td>990033</td>\n",
       "      <td>991081</td>\n",
       "      <td>991975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            2017-02-14  2017-02-15  2017-02-16  2017-02-17  2017-02-18  \\\n",
       "Fillon          423181      424011      425149      426014      426789   \n",
       "Hamon           326739      327730      328988      329775      330478   \n",
       "Le Pen         1272977     1274053     1275497     1276784     1278058   \n",
       "Macron           57998      496473      499164      501489      503556   \n",
       "MÃ©lenchon      964205      965153      966236      967289      968269   \n",
       "\n",
       "            2017-02-19  2017-02-20  2017-02-21  2017-02-22  2017-02-23  \\\n",
       "Fillon          427675      428638      429347      430143      430835   \n",
       "Hamon           331323      331974      332387      332865      333374   \n",
       "Le Pen         1279544     1281410     1284466     1287438     1289158   \n",
       "Macron          505678      508232      510271      513332      515402   \n",
       "MÃ©lenchon      969236      970551      971523      972501      973566   \n",
       "\n",
       "               ...      2017-03-04  2017-03-05  2017-03-06  2017-03-07  \\\n",
       "Fillon         ...          441924      445218      447365      448673   \n",
       "Hamon          ...          337695      338944      339670      340218   \n",
       "Le Pen         ...         1307868     1309959     1312222     1313884   \n",
       "Macron         ...          536933      539827      542253      544300   \n",
       "MÃ©lenchon     ...          982680      984215      985415      986502   \n",
       "\n",
       "            2017-03-08  2017-03-09  2017-03-10  2017-03-11  2017-03-12  \\\n",
       "Fillon          449698      450722      451641      452544      453580   \n",
       "Hamon           340815      341421      342218      342576      342768   \n",
       "Le Pen         1315306     1316938     1318486     1319819     1321599   \n",
       "Macron          546901      549529      551699      553740      556027   \n",
       "MÃ©lenchon      987424      988388      989204      990033      991081   \n",
       "\n",
       "            2017-03-13  \n",
       "Fillon          454327  \n",
       "Hamon           342946  \n",
       "Le Pen         1323344  \n",
       "Macron          558547  \n",
       "MÃ©lenchon      991975  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = pd.read_json(path + '6_fb_likes.json', orient='split')\n",
    "# a=a.sort_index(axis=0)\n",
    "# a\n",
    "b = pd.read_json(path + '0_tw_followers.json', orient='split')\n",
    "b\n",
    "# df = pd.concat([b,a], axis=1)\n",
    "# df.to_json('data/1_tw_mentions.json', orient='split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "folder = 'data/'\n",
    "for tex, subdir, files in os.walk(folder):\n",
    "    for file in files:\n",
    "        print(tex, subdir, file)\n",
    "#         save_metrics(pd.read_json(folder + file, orient='split'),\n",
    "#                      date=datetime.strptime(file[:-5], '%Y-%m-%d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
