{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "# coding: utf-8\n",
    "\n",
    "import sys\n",
    "import requests\n",
    "from datetime import date, datetime, timedelta\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "if sys.version_info[0] == 2:\n",
    "    import urllib2 as ul # Python2\n",
    "else:\n",
    "    import urllib.request as ul # Python3\n",
    "import json\n",
    "\n",
    "\n",
    "def FacebookPageData(page_id, access_token):\n",
    "    \n",
    "    # construct the URL string\n",
    "    base = 'https://graph.facebook.com/v2.8'\n",
    "    node = '/' + page_id\n",
    "    parameters = '/?access_token=%s&fields=name,talking_about_count,fan_count' % access_token\n",
    "    url = base + node + parameters\n",
    "    \n",
    "    # retrieve data\n",
    "    response = ul.urlopen(url)\n",
    "    data = json.loads(response.read().decode('utf-8'))\n",
    "    \n",
    "    print('Facebook page :', data['name'])\n",
    "    return [int(data[metric]) for metric in ['fan_count', 'talking_about_count']]\n",
    "\n",
    "def YoutubePageData(page_id, access_token):\n",
    "    base = 'https://www.googleapis.com/youtube/v3/channels'\n",
    "    parameters = '?part=statistics&id=' + page_id + '&key=' + access_token\n",
    "    url = base + parameters\n",
    "    \n",
    "    # retrieve data\n",
    "    response = ul.urlopen(url)\n",
    "    data = json.loads(response.read().decode('utf-8'))\n",
    "    statistics = data['items'][0]['statistics']\n",
    "\n",
    "    return [int(statistics[metric]) for metric in ['subscriberCount', 'viewCount', 'videoCount']]\n",
    "\n",
    "def YoutubeVideosData(page_id, access_token):\n",
    "    base = 'https://www.googleapis.com/youtube/v3/search'\n",
    "    parameters = '?order=date&part=snippet&channelId=' + page_id + '&maxResults=10&key=' + access_token\n",
    "    url = base + parameters\n",
    "    \n",
    "    # retrieve list of the most recently published videos on the channel (10 or less)\n",
    "    response = ul.urlopen(url)\n",
    "    data = json.loads(response.read().decode('utf-8'))\n",
    "    videoIds = [e['id']['videoId'] for e in data['items'] if 'videoId' in e['id']]\n",
    "    \n",
    "    base = 'https://www.googleapis.com/youtube/v3/videos'\n",
    "    parameters = '?part=statistics&id=' + ','.join(videoIds) + '&key=' + access_token\n",
    "    url = base + parameters\n",
    "    \n",
    "    response = ul.urlopen(url)\n",
    "    data = json.loads(response.read().decode('utf-8'))\n",
    "    keys = data['items'][0]['statistics'].keys() # list of metrics\n",
    "    n = len(data['items'])\n",
    "    \n",
    "    # Construction du dictionnaire des valeurs moyennes pour chaque clé sur les vidéos analysées\n",
    "    videoStats = {key: int(round(sum([int(e['statistics'][key]) for e in data['items']]) / n)) for key in keys}\n",
    "    \n",
    "    print('Getting average metrics for the latest', n, 'videos of the channel')\n",
    "\n",
    "    return [videoStats[metric] for metric in ['viewCount', 'likeCount', 'dislikeCount']]\n",
    "\n",
    "def get_metrics():\n",
    "    df = pd.DataFrame()\n",
    "    print('Maj du', today)\n",
    "\n",
    "    for candidate in accounts:\n",
    "        print('-' * 20)\n",
    "        print(candidate)\n",
    "        print('-' * 20)\n",
    "\n",
    "        stats = {}\n",
    "        try: # Twitter : [tweets, followers]\n",
    "            print('Analyzing Twitter account', accounts[candidate][2])\n",
    "            soup = BeautifulSoup(requests.get('https://twitter.com/' + accounts[candidate][2] + '?lang=en').text, 'lxml')\n",
    "            stats_tw = [int(tag.attrs['title'].replace(',', '').split(' ')[0])\n",
    "                        for tag in soup.find_all(class_='ProfileNav-stat', limit=3) if 'title' in tag.attrs]\n",
    "        except:\n",
    "            stats_tw = ['-', '-', '-']\n",
    "            print('Profil Twitter : une erreur est survenue...')\n",
    "\n",
    "        _, _, stats['0_tw_followers'] = stats_tw\n",
    "\n",
    "        if accounts[candidate][0] is not None:\n",
    "            print('Scanning Youtube Channel')\n",
    "            try: # Youtube [abonnés, total vues, nombre de vidéos]\n",
    "                stats_yt = YoutubePageData(accounts[candidate][0], google_key)\n",
    "            except:\n",
    "                stats_yt = ['-', '-', '-']\n",
    "                print('Page Youtube : une erreur est survenue...')\n",
    "            try: # Youtube [moyenne vues 10 vidéos, moyenne likes 10 vidéos, moyenne dislikes 10 vidéos]\n",
    "                stats_yt2 = YoutubeVideosData(accounts[candidate][0], google_key)\n",
    "            except:\n",
    "                stats_yt2 = ['-', '-', '-']\n",
    "                print('Vidéos Youtube : une erreur est survenue...')\n",
    "        else:\n",
    "            print('No Youtube Channel')\n",
    "            stats_yt, stats_yt2 = ['-', '-', '-'], ['-', '-', '-']\n",
    "\n",
    "        stats['2_yt_subscribers'], _, _ = stats_yt\n",
    "        _, stats['3_yt_like_count'], stats['4_yt_dislike_count'] = stats_yt2\n",
    "\n",
    "        try:\n",
    "            pass\n",
    "            #stats['4_yt_reaction_rate'] = round((float(stats_yt2[1] + stats_yt2[2]) / stats_yt2[0]) * 100, 1)\n",
    "            #stats['5_yt_satisfaction_rate'] = round((float(stats_yt2[1]) / (stats_yt2[2] + stats_yt2[1])) * 100, 1)\n",
    "        except:\n",
    "            pass\n",
    "            #stats['4_yt_reaction_rate'] = '-'\n",
    "            #stats['5_yt_satisfaction_rate'] = '-'\n",
    "\n",
    "        try: # Facebook : [likes, people talking about this]\n",
    "            stats_fb = FacebookPageData(accounts[candidate][1], access_token)\n",
    "        except:\n",
    "            stats_fb = ['-', '-']\n",
    "            print('Page Facebook : une erreur est survenue...')\n",
    "\n",
    "        stats['6_fb_likes'], stats['7_fb_talking_about'] = stats_fb\n",
    "\n",
    "        print()\n",
    "        print(stats)\n",
    "\n",
    "        # ajout de la ligne du candidat dans le dataframe\n",
    "        rec = pd.DataFrame([stats.values()], columns=stats.keys(), index=[candidate])\n",
    "        df = df.append(rec, verify_integrity=False)\n",
    "\n",
    "    # ajout de la colonne des mentions twitter sur 3 jours\n",
    "    #tweet_data = pd.read_json('/var/www/html/decompte/popcontest.json', orient='column')\n",
    "    tweet_data = pd.read_json('popcontest.json', orient='column')\n",
    "    names, counts = [e['name'] for e in tweet_data['children']], [e['size'] for e in tweet_data['children']]\n",
    "    tweet_df = pd.DataFrame(counts, columns=['1_tw_mentions'], index=names)\n",
    "    tweet_df.fillna(value='-', inplace=True)\n",
    "\n",
    "    df = pd.concat([df, tweet_df], axis=1, join_axes=[df.index])\n",
    "    return df\n",
    "\n",
    "def save_metrics(df, timestamp):\n",
    "    # sauvegarde des colonnes du dataframe dans les différents .json\n",
    "    for metric in df:\n",
    "        try:\n",
    "            current_df = pd.read_json(path + metric + '.json', orient='split')\n",
    "            \n",
    "            if timestamp in current_df:\n",
    "                print('Fichier json deja a jour pour', metric)\n",
    "                continue\n",
    "                \n",
    "            current_df = pd.concat([current_df, df[metric]], axis=1)\n",
    "            \n",
    "        except ValueError: # si le fichier n'existe pas\n",
    "            current_df = pd.DataFrame(df[metric], columns=[metric], index=[df.index])\n",
    "\n",
    "        current_df.rename(columns={metric:timestamp}, inplace=True)\n",
    "        current_df.fillna(value='-', inplace=True)\n",
    "        current_df.to_json(path + metric + '.json', orient='split')\n",
    "        print('Data saved as ' + path + metric + '.json')\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# {Candidat : [Chaine Youtube, Compte Facebook, Compte Twitter]}\n",
    "accounts = {#'Alliot-Marie': [None, 'MAlliotMarie', 'MAlliotMarie'],\n",
    "           #'Arthaud': ['UCZsh-MrJftAOP_-ZgRgLScw', 'nathaliearthaud', 'n_arthaud'],\n",
    "           #'Bayrou': [None, 'bayrou', 'bayrou'],\n",
    "           #'Cheminade': ['UCCPw8MX-JcsiTzItY-qq1Fg', 'Jcheminade', 'Jcheminade'],\n",
    "           #'Dupont-Aignan': ['UCfA5DnCDX3Ixy5QOAMGtBlA', 'nicolasdupontaignan', 'dupontaignan'],\n",
    "           'Fillon': ['UCp1R4BFJrKw34PfUc3GDLkw', 'FrancoisFillon', 'francoisfillon'],\n",
    "           'Hamon': ['UCcMryUp6ME3BvP2alkS1dKg', 'hamonbenoit', 'benoithamon'],\n",
    "           #'Jadot': ['UCsUMhb2ygeTSS2mXLTIDHMQ', 'yannick.jadot', 'yjadot'],\n",
    "           'Le Pen': ['UCU3z3px1_RCqYBwrs8LJVWg', 'MarineLePen', 'MLP_officiel'],\n",
    "           'Macron': ['UCJw8np695wqWOaKVhFjkRyg', 'EmmanuelMacron', 'emmanuelmacron'],\n",
    "           u'Mélenchon': ['UCk-_PEY3iC6DIGJKuoEe9bw', 'JLMelenchon', 'JLMelenchon'],\n",
    "           #'Poutou': [None, 'poutou.philippe', 'PhilippePoutou']\n",
    "}\n",
    "\n",
    "app_id = \"615202351999343\"\n",
    "app_secret = \"ea787efd843d1de746817ec6e9bf7e94\"\n",
    "access_token = app_id + \"|\" + app_secret\n",
    "google_key = 'AIzaSyBkRrj_kFDUv-T76CJaI3Pd-g3v7UY4GMA'\n",
    "\n",
    "today = (datetime.utcnow() + timedelta(hours=1)).date()\n",
    "fname = str(today) + '.json'\n",
    "path = 'metric_data/' # save path\n",
    "#path = '/var/www/html/duel/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maj du 2017-03-15\n",
      "--------------------\n",
      "Macron\n",
      "--------------------\n",
      "Analyzing Twitter account emmanuelmacron\n",
      "Scanning Youtube Channel\n",
      "Getting average metrics for the latest 10 videos of the channel\n",
      "Facebook page : Emmanuel Macron\n",
      "\n",
      "{'3_yt_like_count': 411, '0_tw_followers': 562765, '6_fb_likes': 211361, '2_yt_subscribers': 10927, '7_fb_talking_about': 59431, '4_yt_dislike_count': 699}\n",
      "--------------------\n",
      "Le Pen\n",
      "--------------------\n",
      "Analyzing Twitter account MLP_officiel\n",
      "Scanning Youtube Channel\n",
      "Getting average metrics for the latest 10 videos of the channel\n",
      "Facebook page : Marine Le Pen\n",
      "\n",
      "{'3_yt_like_count': 263, '0_tw_followers': 1326503, '6_fb_likes': 1251073, '2_yt_subscribers': 15850, '7_fb_talking_about': 150244, '4_yt_dislike_count': 17}\n",
      "--------------------\n",
      "Fillon\n",
      "--------------------\n",
      "Analyzing Twitter account francoisfillon\n",
      "Scanning Youtube Channel\n",
      "Getting average metrics for the latest 10 videos of the channel\n",
      "Facebook page : François Fillon\n",
      "\n",
      "{'3_yt_like_count': 154, '0_tw_followers': 455936, '6_fb_likes': 306812, '2_yt_subscribers': 4607, '7_fb_talking_about': 68269, '4_yt_dislike_count': 42}\n",
      "--------------------\n",
      "Mélenchon\n",
      "--------------------\n",
      "Analyzing Twitter account JLMelenchon\n",
      "Scanning Youtube Channel\n",
      "Getting average metrics for the latest 10 videos of the channel\n",
      "Facebook page : Jean-Luc Mélenchon\n",
      "\n",
      "{'3_yt_like_count': 5370, '0_tw_followers': 994212, '6_fb_likes': 683467, '2_yt_subscribers': 233165, '7_fb_talking_about': 145153, '4_yt_dislike_count': 58}\n",
      "--------------------\n",
      "Hamon\n",
      "--------------------\n",
      "Analyzing Twitter account benoithamon\n",
      "Scanning Youtube Channel\n",
      "Getting average metrics for the latest 10 videos of the channel\n",
      "Facebook page : Benoît Hamon\n",
      "\n",
      "{'3_yt_like_count': 46, '0_tw_followers': 343673, '6_fb_likes': 140120, '2_yt_subscribers': 5620, '7_fb_talking_about': 41711, '4_yt_dislike_count': 11}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "save_metrics() missing 1 required positional argument: 'timestamp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-75c1a83a1deb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msave_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: save_metrics() missing 1 required positional argument: 'timestamp'"
     ]
    }
   ],
   "source": [
    "save_metrics(get_metrics(), today)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
