{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "# coding: utf-8\n",
    "\n",
    "import sys\n",
    "import requests\n",
    "from datetime import date, datetime, timedelta\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "if sys.version_info[0] == 2:\n",
    "    import urllib2 as ul # Python2\n",
    "else:\n",
    "    import urllib.request as ul # Python3\n",
    "import json\n",
    "\n",
    "\n",
    "def FacebookPageData(page_id, access_token):\n",
    "    \n",
    "    # construct the URL string\n",
    "    base = 'https://graph.facebook.com/v2.8'\n",
    "    node = '/' + page_id\n",
    "    parameters = '/?access_token=%s&fields=name,talking_about_count,fan_count' % access_token\n",
    "    url = base + node + parameters\n",
    "    \n",
    "    # retrieve data\n",
    "    response = ul.urlopen(url)\n",
    "    data = json.loads(response.read().decode('utf-8'))\n",
    "    \n",
    "    print('Facebook page :', data['name'])\n",
    "    return [int(data[metric]) for metric in ['fan_count', 'talking_about_count']]\n",
    "\n",
    "def YoutubePageData(page_id, access_token):\n",
    "    base = 'https://www.googleapis.com/youtube/v3/channels'\n",
    "    parameters = '?part=statistics&id=' + page_id + '&key=' + access_token\n",
    "    url = base + parameters\n",
    "    \n",
    "    # retrieve data\n",
    "    response = ul.urlopen(url)\n",
    "    data = json.loads(response.read().decode('utf-8'))\n",
    "    statistics = data['items'][0]['statistics']\n",
    "\n",
    "    return [int(statistics[metric]) for metric in ['subscriberCount', 'viewCount', 'videoCount']]\n",
    "\n",
    "def YoutubeVideosData(page_id, access_token):\n",
    "    base = 'https://www.googleapis.com/youtube/v3/search'\n",
    "    parameters = '?order=date&part=snippet&channelId=' + page_id + '&maxResults=10&key=' + access_token\n",
    "    url = base + parameters\n",
    "    \n",
    "    # retrieve list of the most recently published videos on the channel (10 or less)\n",
    "    response = ul.urlopen(url)\n",
    "    data = json.loads(response.read().decode('utf-8'))\n",
    "    videoIds = [e['id']['videoId'] for e in data['items'] if 'videoId' in e['id']]\n",
    "    \n",
    "    base = 'https://www.googleapis.com/youtube/v3/videos'\n",
    "    parameters = '?part=statistics&id=' + ','.join(videoIds) + '&key=' + access_token\n",
    "    url = base + parameters\n",
    "    \n",
    "    response = ul.urlopen(url)\n",
    "    data = json.loads(response.read().decode('utf-8'))\n",
    "\n",
    "    df_stats = pd.DataFrame([item['statistics'] for item in data['items']]).fillna(value=0).astype(int)\n",
    "    n = len(df_stats.index)\n",
    "    print('Getting average metrics for the latest', n, 'videos of the channel')\n",
    "\n",
    "    return [df_stats[metric].mean() for metric in ['viewCount', 'likeCount', 'dislikeCount']]\n",
    "\n",
    "def get_metrics():\n",
    "    # {Candidat : [Chaine Youtube, Compte Facebook, Compte Twitter]}\n",
    "    accounts = {#'Alliot-Marie': [None, 'MAlliotMarie', 'MAlliotMarie'],\n",
    "               #'Arthaud': ['UCZsh-MrJftAOP_-ZgRgLScw', 'nathaliearthaud', 'n_arthaud'],\n",
    "               #'Bayrou': [None, 'bayrou', 'bayrou'],\n",
    "               #'Cheminade': ['UCCPw8MX-JcsiTzItY-qq1Fg', 'Jcheminade', 'Jcheminade'],\n",
    "               #'Dupont-Aignan': ['UCfA5DnCDX3Ixy5QOAMGtBlA', 'nicolasdupontaignan', 'dupontaignan'],\n",
    "               'Fillon': ['UCp1R4BFJrKw34PfUc3GDLkw', 'FrancoisFillon', 'francoisfillon'],\n",
    "               'Hamon': ['UCcMryUp6ME3BvP2alkS1dKg', 'hamonbenoit', 'benoithamon'],\n",
    "               #'Jadot': ['UCsUMhb2ygeTSS2mXLTIDHMQ', 'yannick.jadot', 'yjadot'],\n",
    "               'Le Pen': ['UCU3z3px1_RCqYBwrs8LJVWg', 'MarineLePen', 'MLP_officiel'],\n",
    "               'Macron': ['UCJw8np695wqWOaKVhFjkRyg', 'EmmanuelMacron', 'emmanuelmacron'],\n",
    "               'Melenchon': ['UCk-_PEY3iC6DIGJKuoEe9bw', 'JLMelenchon', 'JLMelenchon'],\n",
    "               #'Poutou': [None, 'poutou.philippe', 'PhilippePoutou']\n",
    "    }\n",
    "\n",
    "    app_id = \"615202351999343\"\n",
    "    app_secret = \"ea787efd843d1de746817ec6e9bf7e94\"\n",
    "    access_token = app_id + \"|\" + app_secret\n",
    "    google_key = 'AIzaSyBkRrj_kFDUv-T76CJaI3Pd-g3v7UY4GMA'\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    for candidate in accounts:\n",
    "        print('-' * 20)\n",
    "\n",
    "        stats = {}\n",
    "        try: # Twitter : [_, tweets, followers]\n",
    "            print('Analyzing Twitter account', accounts[candidate][2])\n",
    "            soup = BeautifulSoup(requests.get('https://twitter.com/' + accounts[candidate][2] + '?lang=en').text, 'lxml')\n",
    "            stats_tw = [int(tag.attrs['title'].replace(',', '').split(' ')[0])\n",
    "                        for tag in soup.find_all(class_='ProfileNav-stat', limit=3) if 'title' in tag.attrs]\n",
    "        except:\n",
    "            stats_tw = ['-', '-', '-']\n",
    "            print('Profil Twitter : une erreur est survenue...')\n",
    "\n",
    "        _, _, stats['0_tw_followers'] = stats_tw\n",
    "\n",
    "        if accounts[candidate][0] is not None:\n",
    "            print('Scanning Youtube Channel')\n",
    "            try: # Youtube [abonnés, total vues, nombre de vidéos]\n",
    "                stats_yt = YoutubePageData(accounts[candidate][0], google_key)\n",
    "            except:\n",
    "                stats_yt = ['-', '-', '-']\n",
    "                print('Page Youtube : une erreur est survenue...')\n",
    "            #try: # Youtube [total vues, compte de likes, compte de dislikes]\n",
    "            stats_yt2 = YoutubeVideosData(accounts[candidate][0], google_key)\n",
    "            #except:\n",
    "            # stats_yt2 = ['-', '-', '-']\n",
    "            # print('Vidéos Youtube : une erreur est survenue...')\n",
    "        else:\n",
    "            print('No Youtube Channel')\n",
    "            stats_yt, stats_yt2 = ['-', '-', '-'], ['-', '-', '-']\n",
    "\n",
    "        stats['2_yt_subscribers'], stats['3_yt_views_count'], stats['x_yt_videos_count'] = stats_yt\n",
    "        _, stats['x_yt_like_count'], stats['x_yt_dislike_count'] = stats_yt2\n",
    "\n",
    "        try:\n",
    "            stats['4_yt_reaction_rate'] = round((float(stats_yt2[1] + stats_yt2[2]) / stats_yt2[0]) * 100, 1)\n",
    "            stats['5_yt_satisfaction_rate'] = round((float(stats_yt2[1]) / (stats_yt2[2] + stats_yt2[1])) * 100, 1)\n",
    "        except:\n",
    "            stats['4_yt_reaction_rate'] = '-'\n",
    "            stats['5_yt_satisfaction_rate'] = '-'\n",
    "\n",
    "        try: # Facebook : [likes, people talking about this]\n",
    "            stats_fb = FacebookPageData(accounts[candidate][1], access_token)\n",
    "        except:\n",
    "            stats_fb = ['-', '-']\n",
    "            print('Page Facebook : une erreur est survenue...')\n",
    "\n",
    "        stats['6_fb_likes'], stats['7_fb_talking_about'] = stats_fb\n",
    "\n",
    "        print()\n",
    "        print(stats)\n",
    "\n",
    "        # ajout de la ligne du candidat dans le dataframe\n",
    "        rec = pd.DataFrame([stats.values()], columns=stats.keys(), index=[candidate])\n",
    "        df = df.append(rec, verify_integrity=False)\n",
    "\n",
    "    df.sort_index(axis=0, inplace=True)\n",
    "    df.fillna(value='-', inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "def save_metrics(df, timestamp): # sauvegarde des colonnes du dataframe dans les différents .json\n",
    "    path = 'data/' # save path\n",
    "    #path = '/var/www/html/metrics/data/'\n",
    "\n",
    "    for metric in df:\n",
    "        try:\n",
    "            current_df = pd.read_json(path + metric + '.json', orient='split')\n",
    "\n",
    "            if timestamp in current_df:\n",
    "                current_df[timestamp] = df[metric]\n",
    "            else:\n",
    "                current_df = pd.concat([current_df, df[metric]], axis=1)\n",
    "                current_df.rename(columns={metric:timestamp}, inplace=True)\n",
    "            \n",
    "        except ValueError: # si le fichier n'existe pas\n",
    "            current_df = pd.DataFrame(df[metric], columns=[metric], index=[df.index])\n",
    "            current_df.rename(columns={metric:timestamp}, inplace=True)\n",
    "        \n",
    "        current_df.to_json(path + metric + '.json', orient='split')\n",
    "        print('Data saved as ' + path + metric + '.json')\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting average metrics for the latest 10 videos of the channel\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5934.3, 187.9, 194.3]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app_id = \"615202351999343\"\n",
    "app_secret = \"ea787efd843d1de746817ec6e9bf7e94\"\n",
    "access_token = app_id + \"|\" + app_secret\n",
    "google_key = 'AIzaSyBkRrj_kFDUv-T76CJaI3Pd-g3v7UY4GMA'\n",
    "\n",
    "YoutubeVideosData('UCJw8np695wqWOaKVhFjkRyg', google_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2017-02-15 00:00:00</th>\n",
       "      <th>2017-02-16 00:00:00</th>\n",
       "      <th>2017-02-17 00:00:00</th>\n",
       "      <th>2017-02-18 00:00:00</th>\n",
       "      <th>2017-02-19 00:00:00</th>\n",
       "      <th>2017-02-20 00:00:00</th>\n",
       "      <th>2017-02-21 00:00:00</th>\n",
       "      <th>2017-02-22 00:00:00</th>\n",
       "      <th>2017-02-23 00:00:00</th>\n",
       "      <th>2017-02-24 00:00:00</th>\n",
       "      <th>...</th>\n",
       "      <th>2017-03-07 00:00:00</th>\n",
       "      <th>2017-03-08 00:00:00</th>\n",
       "      <th>2017-03-09 00:00:00</th>\n",
       "      <th>2017-03-10 00:00:00</th>\n",
       "      <th>2017-03-11 00:00:00</th>\n",
       "      <th>2017-03-12 00:00:00</th>\n",
       "      <th>2017-03-13 00:00:00</th>\n",
       "      <th>2017-03-14 00:00:00</th>\n",
       "      <th>2017-03-15 00:00:00</th>\n",
       "      <th>2017-03-16 00:00:00</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fillon</th>\n",
       "      <td>424011</td>\n",
       "      <td>425149</td>\n",
       "      <td>426014</td>\n",
       "      <td>426789</td>\n",
       "      <td>427675</td>\n",
       "      <td>428638</td>\n",
       "      <td>429347</td>\n",
       "      <td>430143</td>\n",
       "      <td>430835</td>\n",
       "      <td>431585</td>\n",
       "      <td>...</td>\n",
       "      <td>448673</td>\n",
       "      <td>449698</td>\n",
       "      <td>450722</td>\n",
       "      <td>451641</td>\n",
       "      <td>452544</td>\n",
       "      <td>453580</td>\n",
       "      <td>454327</td>\n",
       "      <td>455009</td>\n",
       "      <td>455953</td>\n",
       "      <td>456524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hamon</th>\n",
       "      <td>327730</td>\n",
       "      <td>328988</td>\n",
       "      <td>329775</td>\n",
       "      <td>330478</td>\n",
       "      <td>331323</td>\n",
       "      <td>331974</td>\n",
       "      <td>332387</td>\n",
       "      <td>332865</td>\n",
       "      <td>333374</td>\n",
       "      <td>333899</td>\n",
       "      <td>...</td>\n",
       "      <td>340218</td>\n",
       "      <td>340815</td>\n",
       "      <td>341421</td>\n",
       "      <td>342218</td>\n",
       "      <td>342576</td>\n",
       "      <td>342768</td>\n",
       "      <td>342946</td>\n",
       "      <td>343235</td>\n",
       "      <td>343684</td>\n",
       "      <td>344026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Le Pen</th>\n",
       "      <td>1274053</td>\n",
       "      <td>1275497</td>\n",
       "      <td>1276784</td>\n",
       "      <td>1278058</td>\n",
       "      <td>1279544</td>\n",
       "      <td>1281410</td>\n",
       "      <td>1284466</td>\n",
       "      <td>1287438</td>\n",
       "      <td>1289158</td>\n",
       "      <td>1290691</td>\n",
       "      <td>...</td>\n",
       "      <td>1313884</td>\n",
       "      <td>1315306</td>\n",
       "      <td>1316938</td>\n",
       "      <td>1318486</td>\n",
       "      <td>1319819</td>\n",
       "      <td>1321599</td>\n",
       "      <td>1323344</td>\n",
       "      <td>1324596</td>\n",
       "      <td>1326549</td>\n",
       "      <td>1328247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Macron</th>\n",
       "      <td>496473</td>\n",
       "      <td>499164</td>\n",
       "      <td>501489</td>\n",
       "      <td>503556</td>\n",
       "      <td>505678</td>\n",
       "      <td>508232</td>\n",
       "      <td>510271</td>\n",
       "      <td>513332</td>\n",
       "      <td>515402</td>\n",
       "      <td>517712</td>\n",
       "      <td>...</td>\n",
       "      <td>544300</td>\n",
       "      <td>546901</td>\n",
       "      <td>549529</td>\n",
       "      <td>551699</td>\n",
       "      <td>553740</td>\n",
       "      <td>556027</td>\n",
       "      <td>558547</td>\n",
       "      <td>560401</td>\n",
       "      <td>562852</td>\n",
       "      <td>564988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Melenchon</th>\n",
       "      <td>965153</td>\n",
       "      <td>966236</td>\n",
       "      <td>967289</td>\n",
       "      <td>968269</td>\n",
       "      <td>969236</td>\n",
       "      <td>970551</td>\n",
       "      <td>971523</td>\n",
       "      <td>972501</td>\n",
       "      <td>973566</td>\n",
       "      <td>974895</td>\n",
       "      <td>...</td>\n",
       "      <td>986502</td>\n",
       "      <td>987424</td>\n",
       "      <td>988388</td>\n",
       "      <td>989204</td>\n",
       "      <td>990033</td>\n",
       "      <td>991081</td>\n",
       "      <td>991975</td>\n",
       "      <td>992721</td>\n",
       "      <td>994265</td>\n",
       "      <td>995636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           2017-02-15  2017-02-16  2017-02-17  2017-02-18  2017-02-19  \\\n",
       "Fillon         424011      425149      426014      426789      427675   \n",
       "Hamon          327730      328988      329775      330478      331323   \n",
       "Le Pen        1274053     1275497     1276784     1278058     1279544   \n",
       "Macron         496473      499164      501489      503556      505678   \n",
       "Melenchon      965153      966236      967289      968269      969236   \n",
       "\n",
       "           2017-02-20  2017-02-21  2017-02-22  2017-02-23  2017-02-24  \\\n",
       "Fillon         428638      429347      430143      430835      431585   \n",
       "Hamon          331974      332387      332865      333374      333899   \n",
       "Le Pen        1281410     1284466     1287438     1289158     1290691   \n",
       "Macron         508232      510271      513332      515402      517712   \n",
       "Melenchon      970551      971523      972501      973566      974895   \n",
       "\n",
       "              ...      2017-03-07  2017-03-08  2017-03-09  2017-03-10  \\\n",
       "Fillon        ...          448673      449698      450722      451641   \n",
       "Hamon         ...          340218      340815      341421      342218   \n",
       "Le Pen        ...         1313884     1315306     1316938     1318486   \n",
       "Macron        ...          544300      546901      549529      551699   \n",
       "Melenchon     ...          986502      987424      988388      989204   \n",
       "\n",
       "           2017-03-11  2017-03-12  2017-03-13  2017-03-14  2017-03-15  \\\n",
       "Fillon         452544      453580      454327      455009      455953   \n",
       "Hamon          342576      342768      342946      343235      343684   \n",
       "Le Pen        1319819     1321599     1323344     1324596     1326549   \n",
       "Macron         553740      556027      558547      560401      562852   \n",
       "Melenchon      990033      991081      991975      992721      994265   \n",
       "\n",
       "           2017-03-16  \n",
       "Fillon         456524  \n",
       "Hamon          344026  \n",
       "Le Pen        1328247  \n",
       "Macron         564988  \n",
       "Melenchon      995636  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_json('data/0_tw_followers.json', orient='split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maj du 2017-03-16\n",
      "--------------------\n",
      "Analyzing Twitter account francoisfillon\n",
      "Scanning Youtube Channel\n",
      "Getting average metrics for the latest 10 videos of the channel\n",
      "Facebook page : François Fillon\n",
      "\n",
      "{'3_yt_views_count': 1101296, '7_fb_talking_about': 61460, '4_yt_reaction_rate': 3.3, 'x_yt_videos_count': 270, '6_fb_likes': 307408, '2_yt_subscribers': 4626, 'x_yt_like_count': 164.2, 'x_yt_dislike_count': 43.6, '0_tw_followers': 456524, '5_yt_satisfaction_rate': 79.0}\n",
      "--------------------\n",
      "Analyzing Twitter account MLP_officiel\n",
      "Scanning Youtube Channel\n",
      "Getting average metrics for the latest 10 videos of the channel\n",
      "Facebook page : Marine Le Pen\n",
      "\n",
      "{'3_yt_views_count': 2311994, '7_fb_talking_about': 142019, '4_yt_reaction_rate': 6.4, 'x_yt_videos_count': 166, '6_fb_likes': 1252148, '2_yt_subscribers': 15946, 'x_yt_like_count': 279.4, 'x_yt_dislike_count': 18.2, '0_tw_followers': 1328247, '5_yt_satisfaction_rate': 93.9}\n",
      "--------------------\n",
      "Analyzing Twitter account emmanuelmacron\n",
      "Scanning Youtube Channel\n",
      "Getting average metrics for the latest 10 videos of the channel\n",
      "Facebook page : Emmanuel Macron\n",
      "\n",
      "{'3_yt_views_count': 890524, '7_fb_talking_about': 59069, '4_yt_reaction_rate': 6.4, 'x_yt_videos_count': 111, '6_fb_likes': 213231, '2_yt_subscribers': 11029, 'x_yt_like_count': 188.3, 'x_yt_dislike_count': 194.3, '0_tw_followers': 564988, '5_yt_satisfaction_rate': 49.2}\n",
      "--------------------\n",
      "Analyzing Twitter account JLMelenchon\n",
      "Scanning Youtube Channel\n",
      "Getting average metrics for the latest 10 videos of the channel\n",
      "Facebook page : Jean-Luc Mélenchon\n",
      "\n",
      "{'3_yt_views_count': 16663579, '7_fb_talking_about': 164061, '4_yt_reaction_rate': 9.9, 'x_yt_videos_count': 443, '6_fb_likes': 686287, '2_yt_subscribers': 233785, 'x_yt_like_count': 4169.6, 'x_yt_dislike_count': 41.6, '0_tw_followers': 995636, '5_yt_satisfaction_rate': 99.0}\n",
      "--------------------\n",
      "Analyzing Twitter account benoithamon\n",
      "Scanning Youtube Channel\n",
      "Getting average metrics for the latest 10 videos of the channel\n",
      "Facebook page : Benoît Hamon\n",
      "\n",
      "{'3_yt_views_count': 472997, '7_fb_talking_about': 41413, '4_yt_reaction_rate': 6.6, 'x_yt_videos_count': 172, '6_fb_likes': 141127, '2_yt_subscribers': 5660, 'x_yt_like_count': 57.0, 'x_yt_dislike_count': 8.4, '0_tw_followers': 344026, '5_yt_satisfaction_rate': 87.2}\n",
      "Data saved as data/3_yt_views_count.json\n",
      "Data saved as data/7_fb_talking_about.json\n",
      "Data saved as data/4_yt_reaction_rate.json\n",
      "Data saved as data/x_yt_videos_count.json\n",
      "Data saved as data/6_fb_likes.json\n",
      "Data saved as data/2_yt_subscribers.json\n",
      "Data saved as data/x_yt_like_count.json\n",
      "Data saved as data/x_yt_dislike_count.json\n",
      "Data saved as data/0_tw_followers.json\n",
      "Data saved as data/5_yt_satisfaction_rate.json\n"
     ]
    }
   ],
   "source": [
    "#__________________________\n",
    "today = (datetime.utcnow() + timedelta(hours=1)).date()\n",
    "print('Maj du', today)\n",
    "\n",
    "save_metrics(get_metrics(), today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
