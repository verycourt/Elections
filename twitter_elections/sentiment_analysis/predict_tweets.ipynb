{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "# coding: utf-8\n",
    "\n",
    "from datetime import date, datetime, timedelta\n",
    "from predict_functions import *\n",
    "from sklearn.externals import joblib\n",
    "import pandas as pd\n",
    "\n",
    "# TODO 0: installer et configurer treetagger sur le serveur\n",
    "\n",
    "# TODO 1: integrer le code qui permet de recuperer les tweets pour un candidat et un jour donnés\n",
    "# (par tranche d'un jour? trois jours pour lisser les résultats?) sous forme de dataframe avec une colonne 'text'\n",
    "\n",
    "# TODO 2: transferer dans un fichier python, upload sur le serveur et programmer un cron (une fois par jour?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "today = (datetime.utcnow() + timedelta(hours=2)).date() # heure d'été, on est en UTC+2 au lieu de +1\n",
    "fname = 'twitter_sentiments_{}.json'.format(today)\n",
    "\n",
    "df_pred = pd.DataFrame()\n",
    "candidates = ['macron', 'fillon']\n",
    "\n",
    "# 1. Chargement du vocabulaire\n",
    "voca = pd.read_json('trained_dict.json').to_dict()[0]\n",
    "\n",
    "for candidate in candidates:\n",
    "    # 2. Chargement des tweets a predire\n",
    "    print('Chargement des tweets du candidat {}'.format(candidate))\n",
    "    # df_tweets = .... (dataframe contenant les tweets a predire dans une colonne 'text', creer un df par candidat)\n",
    "\n",
    "    # 3. Creation des features et de la matrice TF-IDF pour la base test\n",
    "    X_test, _, _ = build_Xy(df_tweets, drop_dups=False, vocab=voca, min_df=3, n_grams=(1,1))\n",
    "\n",
    "    # 4. Chargement du modele entraine\n",
    "    clf = joblib.load('trained_logistic_regression.pkl')\n",
    "\n",
    "    # 5. Prediction\n",
    "    y_pred = clf.predict(X_test)\n",
    "    results = [np.sum(y_pred==label) / len(y_pred) for label in [1, 0, -1]]\n",
    "\n",
    "    # ajout de la ligne du candidat dans le dataframe\n",
    "    rec = pd.DataFrame([results], columns=['pos', 'neu', 'neg'], index=[candidate])\n",
    "    df_pred = df_pred.append(rec, verify_integrity=False)\n",
    "\n",
    "# 6. Sauvegarder les predictions (dans un dataframe puis un json par exemple?)\n",
    "df_pred.to_json(fname)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
