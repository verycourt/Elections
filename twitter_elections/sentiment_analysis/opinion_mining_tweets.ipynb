{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Approche : mélanger analyse lexicale et par apprentissage.\n",
    "\n",
    "1. Analyse lexicale des tweets :\n",
    "    - POS tagging, lemmisation\n",
    "    - Traduction des mots en Anglais pour pouvoir utiliser Sentiwordnet et obtenir la polarité des mots\n",
    "\n",
    "2. Application d'un modèle d'apprentissage supervisé :\n",
    "    - HMM, SVM, etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Liste des POS tags français : http://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/data/french-tagset.html\n",
    "\n",
    "Etudier la possibilité d'ajout de lexiques d'opinion en Français : http://alpage.inria.fr/~sagot/wolf.html, http://sites.univ-provence.fr/wpsycle/outils_recherche/liwc/FrenchLIWCDictionary_V1_1.dic, http://sites.univ-provence.fr/~wpsycle/outils_recherche/outils_recherche.html#emotaix\n",
    "\n",
    "Voir l'approche compositionnelle : Moilanen 2007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "import treetaggerwrapper\n",
    "import time\n",
    "import gc\n",
    "\n",
    "import pymongo as pym\n",
    "#import nltk.data\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "import stop_words\n",
    "#from nltk.stem import *\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mongo_to_df(collection, n_last_tweets=0, retweet=False):\n",
    "    tweets = collection.find(filter={'text':{'$exists':True}}, \n",
    "                             projection={'_id':False}).sort('$natural',-1).limit(n_last_tweets)\n",
    "    df = pd.DataFrame()\n",
    "    listTweets, listCandidats, listSentiments = [], [], []\n",
    "    \n",
    "    for t in tweets: \n",
    "        if not retweet: # filtrage des retweets\n",
    "            if 'rt @' in t['text']:\n",
    "                continue\n",
    "\n",
    "        if t['text']: # test si liste non vide\n",
    "            listTweets.append(t['text'])\n",
    "            try:\n",
    "                listCandidats.append(t['candidat'])\n",
    "            except:\n",
    "                listCandidats.append(None)\n",
    "            \n",
    "            try:\n",
    "                listSentiments.append(t['sentiment'])\n",
    "            except:\n",
    "                listSentiments.append(None)\n",
    "    \n",
    "    df['text'], df['candidat'], df['sentiment'] = listTweets, listCandidats, listSentiments\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_tweets(client, spellcheck=True, label_auto=True, retweet=True):\n",
    "    \n",
    "    if spellcheck:\n",
    "        collection = client.tweet.spellchecked\n",
    "        df_tweets = mongo_to_df(collection, n_last_tweets=0, retweet=retweet)\n",
    "        print('Correction orthographique activée.')\n",
    "        if not label_auto:\n",
    "            df_tweets = df_tweets[:client.tweet.train.count()]\n",
    "    else:\n",
    "        collection = client.tweet.train\n",
    "        df_tweets = mongo_to_df(collection, n_last_tweets=0, retweet=retweet)\n",
    "        print('Correction orthographique desactivée.')\n",
    "        if label_auto:\n",
    "            # Base annotée automatiquement, sur la base des hashtags (uniquement des tweets positifs)\n",
    "            collection = client.tweet.labelised\n",
    "            df_tweets_auto = mongo_to_df(collection, n_last_tweets=0, retweet=retweet)\n",
    "            print('Ajout des tweets labélisés automatiquement...')\n",
    "            print('{} tweets ajoutés.'.format(df_tweets_auto['text'].count()))\n",
    "            df_tweets = pd.concat([df_tweets, df_tweets_auto], axis=0, ignore_index=True)\n",
    "        \n",
    "    print('\\n{} tweets au total récupérés pour entraînement, répartis comme suit :'.format(df_tweets['text'].count()))\n",
    "    print(df_tweets['sentiment'].value_counts())\n",
    "    print(df_tweets['candidat'].value_counts())\n",
    "        \n",
    "    return df_tweets\n",
    "\n",
    "\n",
    "def process_texts(list_of_texts, pos_tag_list, stop_words):\n",
    "    # Processing the tweets (POS tagging, lemmatization, spellchecking)\n",
    "    tagger = treetaggerwrapper.TreeTagger(TAGLANG='fr')\n",
    "    list_of_processed_texts = []\n",
    "    \n",
    "    for text in list_of_texts:\n",
    "        # Etape de filtrage\n",
    "        text = re.sub(r'\\w*…', '', text) # mot tronqué par Twitter\n",
    "        text = re.sub(r'(?:htt)\\S*', '', text) # retrait des liens http\n",
    "        text = re.sub(r'\\n', ' ', text) # retrait des sauts de ligne\n",
    "        text = re.sub(r'\\xad', '-', text)\n",
    "        text = re.sub(r'@\\w*', '', text) # retrait des mentions @ (ne détecte pas @XXX@...)\n",
    "        text = re.sub(r'\\.{3,}', '...', text) # ....... => points de suspension\n",
    "        text = re.sub(r'(?=\\.\\w)(\\.)', '. ', text) # remplacer un point entre deux mots 'A.B' par 'A. B'\n",
    "        #text = re.sub(r'\\[a-zA-Z]*(?!\\S)', '', text) # retrait de ce qui n'est pas un mot\n",
    "        #text = re.sub(r'^rt.*: ', '', text) # retrait de la mention retweet\n",
    "        #text = re.sub(r'\\d', '', text) # retrait des chiffres\n",
    "        #text = re.sub(r',;!?\\/\\*(){}«»', ' ', text)\n",
    "        #text = re.sub('|'.join(['’', '_', '/', '-', '\\'', '“', '\\.']), ' ', text)\n",
    "        #text = re.sub('|'.join([elem + '\\'' for elem in 'cdjlmnst']), '', text) # apostrophes\n",
    "        \n",
    "        # TODO: (optionnel) retirer les # avant d'utiliser TreeTagger\n",
    "        # puis les remettre avec le tag HASH|\n",
    "        \n",
    "        # TODO: correction orthographique des tweets\n",
    "        \n",
    "        tags = tagger.tag_text(text)\n",
    "        \n",
    "        try:\n",
    "            tagged_text = ['{}|{}'.format(t.split('\\t')[1], t.split('\\t')[2]) for t in tags\n",
    "                           if (t.split('\\t')[2] not in stop_words\n",
    "                               and t.split('\\t')[1] in pos_tag_list)]\n",
    "        except:\n",
    "            tagged_text = ['ERREUR']\n",
    "        \n",
    "        # append les HASH|#...\n",
    "        # TODO: (optionnel) gérer les accents sur les mots\n",
    "        list_of_processed_texts.append(tagged_text)\n",
    "        \n",
    "    return list_of_processed_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_Xy(df_tweets, pos_tags_to_keep, stop_words):\n",
    "    # Tweet feature extraction\n",
    "    # TODO: faire des tests en ajoutant/retirant des features\n",
    "    hashtag = np.array([t.count('#') / 1. for t in df_tweets['text']])\n",
    "    links = np.array([t.count('http') / 1. for t in df_tweets['text']])\n",
    "    at = np.array([t.count('@') / 1. for t in df_tweets['text']])\n",
    "    n_car = np.array([np.log(len(t))/4 / 1. for t in df_tweets['text']])\n",
    "    n_words = np.array([np.log(len(t.split(' '))) / 2 for t in df_tweets['text']])\n",
    "    n_2points = np.array([t.count(':') / 1. for t in df_tweets['text']])\n",
    "    n_exc = np.array([t.count('!') / 1. for t in df_tweets['text']])\n",
    "    n_int = np.array([t.count('?') / 1. for t in df_tweets['text']])\n",
    "    n_quotes = np.array([(t.count('\"') + t.count('»')) / 2 for t in df_tweets['text']])\n",
    "\n",
    "    print('Tagging des tweets en cours...')\n",
    "    tweet_list = process_texts(df_tweets['text'], pos_tags_to_keep, stop_words)\n",
    "    #TODO: concatener la liste au df. Retirer les doublons du df avec drop_duplicates.\n",
    "    # Recreer la liste des tweets sans doublons à partir de la colonne\n",
    "\n",
    "    print('TreeTagger a renvoyé {} erreur(s).'.format(tweet_list.count('ERREUR')))\n",
    "\n",
    "    # Building feature matrix\n",
    "    # TODO: jouer sur les min et max df\n",
    "    print('\\nCréation de la matrice de features...')\n",
    "    vectorizer = TfidfVectorizer(strip_accents=None, analyzer='word', decode_error='strict',\n",
    "                                use_idf=False, norm=None, binary=False, min_df=4, max_df=1.0, ngram_range=(1,2))\n",
    "    \n",
    "    tfidf = vectorizer.fit_transform([' '.join(tweet) for tweet in tweet_list])\n",
    "    X = pd.DataFrame(tfidf.toarray())\n",
    "\n",
    "    X_added_features = pd.DataFrame(data={'#': hashtag,\n",
    "                                          #'http': links,\n",
    "                                          '@': at,\n",
    "                                          'n_car': n_car,\n",
    "                                          'n_words': n_words,\n",
    "                                          ':': n_2points,\n",
    "                                          '!': n_exc,\n",
    "                                          '?': n_int,\n",
    "                                          '\"\"': n_quotes\n",
    "                                         })\n",
    "\n",
    "    X = pd.concat([X, X_added_features], axis=1)\n",
    "    y = df_tweets['sentiment']\n",
    "    \n",
    "    Xy = pd.concat([X, y], axis=1)\n",
    "    Xy.drop_duplicates(inplace=True)\n",
    "    print('{} doublons retirés ({} documents restants).'.format(X.shape[0] - Xy.shape[0], Xy.shape[0]))\n",
    "    print(Xy[:5])\n",
    "\n",
    "    return Xy.drop('sentiment', axis=1), Xy['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_best_params(X, y, model, params_to_test, cut=1):\n",
    "    if model not in ['logistic', 'svc', 'nb', 'rf']:\n",
    "        print('Il faut choisir un modèle parmi logistic, svc, rf et nb.')\n",
    "        return\n",
    "    \n",
    "    # Building train & test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X[:-cut], y[:-cut], test_size = 0.15)\n",
    "    X_train = pd.concat([X_train, X[-cut:]], axis=0)\n",
    "    y_train = pd.concat([y_train, y[-cut:]], axis=0)\n",
    "    \n",
    "    # mélange des lignes\n",
    "    rng = np.random.randint(1000)\n",
    "    X_train = X_train.sample(frac=1.0, replace=False, random_state=rng)\n",
    "    y_train = y_train.sample(frac=1.0, replace=False, random_state=rng)\n",
    "    n_samples, vocabulaire = X.shape\n",
    "\n",
    "    print(\"Répartition dans le dataset de train ({} tweets) : \\n\".format(len(y_train)),\n",
    "          '\\tNégatif : {:.1f}'.format(len(np.extract(y_train == -1, y_train)) / len(y_train) * 100),\n",
    "          '%\\n\\tPositif : {:.1f}'.format(len(np.extract(y_train == 1, y_train)) / len(y_train) * 100), '%')\n",
    "    print(\"Répartition dans le dataset de test ({} tweets) : \\n\".format(len(y_test)),\n",
    "          '\\tNégatif : {:.1f}'.format(len(np.extract(y_test == -1, y_test)) / len(y_test) * 100),\n",
    "          '%\\n\\tPositif : {:.1f}'.format(len(np.extract(y_test == 1, y_test)) / len(y_test) * 100), '%')\n",
    "    print('Tweets : ' + str(n_samples) + ' / ' + 'N-grams : ' + str(vocabulaire))\n",
    "\n",
    "    # Choice of models\n",
    "    if model == 'logistic':\n",
    "        clf = LogisticRegression(max_iter=4000, class_weight='balanced', multi_class='ovr')\n",
    "    if model == 'svc':\n",
    "        clf = LinearSVC(class_weight='balanced')\n",
    "    if model == 'nb' :\n",
    "        clf = MultinomialNB()\n",
    "    if model == 'rf' :\n",
    "        clf = RandomForestClassifier(criterion='gini', max_depth=None, max_features='auto',\n",
    "                                     bootstrap=True, n_jobs=-1, verbose=0, class_weight='balanced_subsample')\n",
    "\n",
    "    gcv = GridSearchCV(clf, params_to_test, verbose=9, n_jobs=-1, cv=4, refit=True)\n",
    "    gcv.fit(X_train, y_train)\n",
    "    print('Les meilleurs paramètres pour {} sont {}.'.format(model, gcv.best_params_))\n",
    "    \n",
    "    # Fit & predict\n",
    "    print('Prédiction sur l\\'ensemble de test avec ces paramètres...')\n",
    "    y_pred = gcv.predict(X_test)\n",
    "\n",
    "    print('Score', np.sum(y_pred == y_test) / len(y_pred))\n",
    "    print('Répartition des prédictions : \\n',\n",
    "          '\\tNégatif : {:.1f}'.format(len(np.extract(y_pred == -1, y_pred)) / len(y_pred) * 100),\n",
    "          '%\\n\\tPositif : {:.1f}'.format(len(np.extract(y_pred == 1, y_pred)) / len(y_pred) * 100), '%')\n",
    "\n",
    "    # matrice de confusion\n",
    "    cf = confusion_matrix(y_test, y_pred)\n",
    "    recall = [cf[i,i]/cf[i,:].sum() for i in range(3)]\n",
    "    precision = [cf[i,i]/cf[:,i].sum() for i in range(3)]\n",
    "    print('\\nMatrice de confusion (ligne: classe réelle, colonne: classe prédite):')\n",
    "    print(cf)\n",
    "    print('Recall (négatif, neutre, positif) : {:.3f}, {:.3f}, {:.3f}'.format(recall[0], recall[1], recall[2]))\n",
    "    print('Précision (négatif, neutre, positif) : {:.3f}, {:.3f}, {:.3f}'.format(precision[0], precision[1], precision[2]))\n",
    "    \n",
    "    return\n",
    "\n",
    "def fit_predict(X, y, clf, cut=1):\n",
    "    \n",
    "    # Building train & test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X[:-cut], y[:-cut], test_size = 0.15)\n",
    "    X_train = pd.concat([X_train, X[-cut:]], axis=0)\n",
    "    y_train = pd.concat([y_train, y[-cut:]], axis=0)\n",
    "    \n",
    "    # mélange des lignes\n",
    "    rng = np.random.randint(1000)\n",
    "    X_train = X_train.sample(frac=1.0, replace=False, random_state=rng)\n",
    "    y_train = y_train.sample(frac=1.0, replace=False, random_state=rng)\n",
    "    n_samples, vocabulaire = X.shape\n",
    "\n",
    "    print(\"Répartition dans le dataset de train ({} tweets) : \\n\".format(len(y_train)),\n",
    "          '\\tNégatif : {:.1f}'.format(len(np.extract(y_train == -1, y_train)) / len(y_train) * 100),\n",
    "          '%\\n\\tPositif : {:.1f}'.format(len(np.extract(y_train == 1, y_train)) / len(y_train) * 100), '%')\n",
    "    print(\"Répartition dans le dataset de test ({} tweets) : \\n\".format(len(y_test)),\n",
    "          '\\tNégatif : {:.1f}'.format(len(np.extract(y_test == -1, y_test)) / len(y_test) * 100),\n",
    "          '%\\n\\tPositif : {:.1f}'.format(len(np.extract(y_test == 1, y_test)) / len(y_test) * 100), '%')\n",
    "    print('Tweets : ' + str(n_samples) + ' / ' + 'N-grams : ' + str(vocabulaire))\n",
    "\n",
    "    \n",
    "    # Fit & predict\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    print('Score', np.sum(y_pred == y_test) / len(y_pred))\n",
    "    print('Répartition des prédictions : \\n',\n",
    "          '\\tNégatif : {:.1f}'.format(len(np.extract(y_pred == -1, y_pred)) / len(y_pred) * 100),\n",
    "          '%\\n\\tPositif : {:.1f}'.format(len(np.extract(y_pred == 1, y_pred)) / len(y_pred) * 100), '%')\n",
    "\n",
    "    # matrice de confusion\n",
    "    cf = confusion_matrix(y_test, y_pred)\n",
    "    recall = [cf[i,i]/cf[i,:].sum() for i in range(3)]\n",
    "    precision = [cf[i,i]/cf[:,i].sum() for i in range(3)]\n",
    "    print('\\nMatrice de confusion (ligne: classe réelle, colonne: classe prédite):')\n",
    "    print(cf)\n",
    "    print('Recall (négatif, neutre, positif) : {:.3f}, {:.3f}, {:.3f}'.format(recall[0], recall[1], recall[2]))\n",
    "    print('Précision (négatif, neutre, positif) : {:.3f}, {:.3f}, {:.3f}'.format(precision[0], precision[1], precision[2]))\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test du TreeTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output du tagger : ['mdr\\tNOM\\tmdr', 'lol\\tNOM\\tlol', ':\\tPUN\\t:', 'test\\tNOM\\ttest', 'nombre\\tNOM\\tnombre', '800\\tNUM\\t@card@', ',\\tPUN\\t,', '000\\tNUM\\t@card@', '€\\tNOM\\t€']\n",
      "Création des features : ['NOM|mdr', 'NOM|lol', 'PUN|:', 'NOM|test', 'NOM|nombre', 'NUM|@card@', 'PUN|,', 'NUM|@card@', 'NOM|€']\n"
     ]
    }
   ],
   "source": [
    "tagger = treetaggerwrapper.TreeTagger(TAGLANG='fr')\n",
    "tags = tagger.tag_text('mdr lol : test nombre 800,000 €')\n",
    "print('Output du tagger :', tags)\n",
    "tagged_text = ['{}|{}'.format(t.split('\\t')[1], t.split('\\t')[2]) for t in tags]\n",
    "print('Création des features :', tagged_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Echantillons de tweets dans la base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 10001 8893\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       " 0    3390\n",
       "-1    3233\n",
       " 1    2270\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = pym.MongoClient('localhost',27017)\n",
    "df_labelised = mongo_to_df(client.tweet.labelised, retweet=True)\n",
    "df_spell = mongo_to_df(client.tweet.spellchecked, retweet=True)\n",
    "df_train = mongo_to_df(client.tweet.train, retweet=True)\n",
    "print(df_spell.shape[0], df_train.shape[0], df_labelised.shape[0])\n",
    "df_labelised['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index out of bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\indexes\\base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   2168\u001b[0m             return self._engine.get_value(s, k,\n\u001b[0;32m-> 2169\u001b[0;31m                                           tz=getattr(series.dtype, 'tz', None))\n\u001b[0m\u001b[1;32m   2170\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas\\index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_value (pandas\\index.c:3557)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas\\index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_value (pandas\\index.c:3240)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas\\index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas\\index.c:4279)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas\\src\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.Int64HashTable.get_item (pandas\\hashtable.c:8564)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas\\src\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.Int64HashTable.get_item (pandas\\hashtable.c:8508)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-347e75649c7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_spell\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m'-'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m'-'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    601\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    604\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\indexes\\base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   2173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2174\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2175\u001b[0;31m                 \u001b[1;32mreturn\u001b[0m \u001b[0mtslib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value_box\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2176\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2177\u001b[0m                 \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas\\tslib.pyx\u001b[0m in \u001b[0;36mpandas.tslib.get_value_box (pandas\\tslib.c:19053)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas\\tslib.pyx\u001b[0m in \u001b[0;36mpandas.tslib.get_value_box (pandas\\tslib.c:18770)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of bounds"
     ]
    }
   ],
   "source": [
    "for i in range(0, 20):\n",
    "    print(df_spell['text'][i])\n",
    "    print(2*'-')\n",
    "    print(df_train['text'][i])\n",
    "    print(10*'-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement des tweets depuis Mongo et création des features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correction orthographique desactivée.\n",
      "Ajout des tweets labélisés automatiquement...\n",
      "8887 tweets ajoutés.\n",
      "\n",
      "16432 tweets au total récupérés pour entraînement, répartis comme suit :\n",
      "-1.0    6972\n",
      " 0.0    6234\n",
      " 1.0    3226\n",
      "Name: sentiment, dtype: int64\n",
      "fillon       2707\n",
      "macron       2542\n",
      "le pen       2136\n",
      "hamon        1044\n",
      "melenchon     239\n",
      "mélenchon     219\n",
      "Name: candidat, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Choix de la base à utiliser\n",
    "client = pym.MongoClient('localhost',27017)\n",
    "df = load_tweets(client, spellcheck=False, label_auto=True, retweet=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jouer avec les paramètres : POS tag à garder, dictionnaire de stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tagging des tweets en cours...\n",
      "TreeTagger a renvoyé 0 erreur(s).\n",
      "\n",
      "Création de la matrice de features...\n",
      "1623 doublons retirés (14809 documents restants).\n",
      "     0    1    2    3    4    5    6    7    8    9    ...      9837    !  \\\n",
      "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0    ...       0.0  0.0   \n",
      "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0    ...       0.0  0.0   \n",
      "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0    ...       0.0  0.0   \n",
      "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0    ...       0.0  2.0   \n",
      "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0    ...       0.0  0.0   \n",
      "\n",
      "    \"\"    #    :    ?    @     n_car   n_words  sentiment  \n",
      "0  0.0  1.0  1.0  0.0  0.0  1.228164  1.522261        1.0  \n",
      "1  0.0  0.0  0.0  0.0  0.0  0.972955  0.972955       -1.0  \n",
      "2  0.0  0.0  1.0  0.0  0.0  1.235411  1.609438       -1.0  \n",
      "3  0.0  1.0  1.0  0.0  1.0  1.235411  1.545521       -1.0  \n",
      "4  0.0  0.0  1.0  2.0  0.0  1.170533  1.242453       -1.0  \n",
      "\n",
      "[5 rows x 9847 columns]\n"
     ]
    }
   ],
   "source": [
    "# Choix des POS tags à conserver\n",
    "all_postags = ['ABR', 'ADJ', 'ADV', 'DET:ART', 'DET:POS', 'INT', 'KON', 'NAM', 'NOM', 'NUM', 'PRO',\n",
    "                   'PRO:DEM', 'PRO:IND', 'PRO:PER', 'PRO:POS', 'PRO:REL', 'PRP', 'PRP:det', 'PUN', 'PUN:cit',\n",
    "                   'SENT', 'SYM', 'VER:cond', 'VER:futu', 'VER:impe', 'VER:impf', 'VER:pper', 'VER:ppre',\n",
    "                   'VER:pres', 'VER:simp', 'VER:subi', 'VER:subp']\n",
    "\n",
    "pos_tags_to_keep = ['ADJ', 'ADV', 'NOM', 'NUM', 'PUN:cit', 'PRO:POS', 'PRO:DEM',\n",
    "                    'VER:cond', 'VER:futu', 'VER:impe', 'VER:impf',\n",
    "                    'VER:pper', 'VER:ppre', 'VER:pres', 'VER:simp', 'VER:subi', 'VER:subp']\n",
    "\n",
    "# Choix des stop words\n",
    "# stops = set(['rt','ds','qd','ss','ns','vs','nn','amp','gt','gd','gds','tt','pr','ac','mm', 'qu',\n",
    "#             '``', 'ca', 'mdr', 'lol', 'dsl', 'cad']\n",
    "#             + list('@ن%£€‘:&;')\n",
    "#             + list('abcdefghijklmnopqrstuvwxyzà')\n",
    "#            + stop_words.get_stop_words(language='fr')\n",
    "#            + stopwords.words('french')\n",
    "#            )\n",
    "stops = set(list('abcdefghijklmnopqrstuvwxyz')\n",
    "#           + ['rt','ds','qd','ss','ns','vs','nn','amp','gt','gd','gds','tt','pr','ac','mm','qu','dsl','cad']\n",
    "           )\n",
    "# TODO: améliorer la liste de stop words\n",
    "\n",
    "X, y = build_Xy(df, pos_tags_to_keep, stops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test avec la regression logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Répartition dans le dataset de train (13787 tweets) : \n",
      " \tNégatif : 45.7 %\n",
      "\tPositif : 21.6 %\n",
      "Répartition dans le dataset de test (1022 tweets) : \n",
      " \tNégatif : 50.4 %\n",
      "\tPositif : 12.4 %\n",
      "Tweets : 14809 / N-grams : 9846\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   4 | elapsed:   43.6s remaining:   43.6s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   44.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   44.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les meilleurs paramètres pour logistic sont {'C': 0.5, 'dual': True, 'penalty': 'l2'}.\n",
      "Prédiction sur l'ensemble de test avec ces paramètres...\n",
      "Score 0.634050880626\n",
      "Répartition des prédictions : \n",
      " \tNégatif : 51.9 %\n",
      "\tPositif : 6.6 %\n",
      "\n",
      "Matrice de confusion (ligne: classe réelle, colonne: classe prédite):\n",
      "[[367 127  21]\n",
      " [103 256  21]\n",
      " [ 60  42  25]]\n",
      "Recall (négatif, neutre, positif) : 0.713, 0.674, 0.197\n",
      "Précision (négatif, neutre, positif) : 0.692, 0.602, 0.373\n"
     ]
    }
   ],
   "source": [
    "params = {'penalty':['l2'], 'dual': [True], 'C' : [.5]}\n",
    "find_best_params(X, y, 'logistic', params, cut=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Répartition dans le dataset de train (13787 tweets) : \n",
      " \tNégatif : 45.6 %\n",
      "\tPositif : 21.7 %\n",
      "Répartition dans le dataset de test (1022 tweets) : \n",
      " \tNégatif : 51.3 %\n",
      "\tPositif : 11.7 %\n",
      "Tweets : 14809 / N-grams : 9846\n",
      "Score 0.617416829746\n",
      "Répartition des prédictions : \n",
      " \tNégatif : 50.8 %\n",
      "\tPositif : 6.4 %\n",
      "\n",
      "Matrice de confusion (ligne: classe réelle, colonne: classe prédite):\n",
      "[[363 140  21]\n",
      " [114 244  20]\n",
      " [ 42  54  24]]\n",
      "Recall (négatif, neutre, positif) : 0.693, 0.646, 0.200\n",
      "Précision (négatif, neutre, positif) : 0.699, 0.557, 0.369\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(C=.5, max_iter=2000, class_weight='balanced', multi_class='ovr',\n",
    "                        penalty='l2', dual=True)\n",
    "fit_predict(X, y, clf, cut=8000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test avec le LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Répartition dans le dataset de train (13337 tweets) : \n",
      " \tNégatif : 44.7 %\n",
      "\tPositif : 21.7 %\n",
      "Répartition dans le dataset de test (1472 tweets) : \n",
      " \tNégatif : 57.8 %\n",
      "\tPositif : 14.7 %\n",
      "Tweets : 14809 / N-grams : 9846\n",
      "Fitting 4 folds for each of 3 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   7 out of  12 | elapsed:  1.4min remaining:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of  12 | elapsed:  1.5min remaining:   29.5s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:  1.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les meilleurs paramètres pour svc sont {'C': 0.02}.\n",
      "Prédiction sur l'ensemble de test avec ces paramètres...\n",
      "Score 0.695652173913\n",
      "Répartition des prédictions : \n",
      " \tNégatif : 56.6 %\n",
      "\tPositif : 8.5 %\n",
      "\n",
      "Matrice de confusion (ligne: classe réelle, colonne: classe prédite):\n",
      "[[654 170  27]\n",
      " [113 282  10]\n",
      " [ 66  62  88]]\n",
      "Recall (négatif, neutre, positif) : 0.769, 0.696, 0.407\n",
      "Précision (négatif, neutre, positif) : 0.785, 0.549, 0.704\n"
     ]
    }
   ],
   "source": [
    "params = {'C' : [.02, .1, 1.]}\n",
    "find_best_params(X, y, 'svc', params, cut=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = LinearSVC(C=.02, class_weight='balanced')\n",
    "fit_predict(X, y, clf, cut=8000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test avec Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Répartition dans le dataset de train (13337 tweets) : \n",
      " \tNégatif : 44.8 %\n",
      "\tPositif : 21.6 %\n",
      "Répartition dans le dataset de test (1472 tweets) : \n",
      " \tNégatif : 56.5 %\n",
      "\tPositif : 15.0 %\n",
      "Tweets : 14809 / N-grams : 9846\n",
      "Fitting 4 folds for each of 3 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   7 out of  12 | elapsed:   26.0s remaining:   18.5s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of  12 | elapsed:   29.8s remaining:    9.9s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:   34.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les meilleurs paramètres pour nb sont {'alpha': 1.0}.\n",
      "Prédiction sur l'ensemble de test avec ces paramètres...\n",
      "Score 0.677989130435\n",
      "Répartition des prédictions : \n",
      " \tNégatif : 55.0 %\n",
      "\tPositif : 14.5 %\n",
      "\n",
      "Matrice de confusion (ligne: classe réelle, colonne: classe prédite):\n",
      "[[619 149  63]\n",
      " [121 264  35]\n",
      " [ 69  37 115]]\n",
      "Recall (négatif, neutre, positif) : 0.745, 0.629, 0.520\n",
      "Précision (négatif, neutre, positif) : 0.765, 0.587, 0.540\n"
     ]
    }
   ],
   "source": [
    "params = {'alpha': [.75, 1., 1.25]}\n",
    "find_best_params(X, y, 'nb', params, cut=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Répartition dans le dataset de train (13337 tweets) : \n",
      " \tNégatif : 44.9 %\n",
      "\tPositif : 21.6 %\n",
      "Répartition dans le dataset de test (1472 tweets) : \n",
      " \tNégatif : 55.6 %\n",
      "\tPositif : 15.1 %\n",
      "Tweets : 14809 / N-grams : 9846\n",
      "Score 0.674592391304\n",
      "Répartition des prédictions : \n",
      " \tNégatif : 56.3 %\n",
      "\tPositif : 13.2 %\n",
      "\n",
      "Matrice de confusion (ligne: classe réelle, colonne: classe prédite):\n",
      "[[617 152  50]\n",
      " [136 263  32]\n",
      " [ 76  33 113]]\n",
      "Recall (négatif, neutre, positif) : 0.753, 0.610, 0.509\n",
      "Précision (négatif, neutre, positif) : 0.744, 0.587, 0.579\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB(alpha=1.)\n",
    "fit_predict(X, y, clf, cut=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Test avec Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Répartition dans le dataset de train (13337 tweets) : \n",
      " \tNégatif : 44.8 %\n",
      "\tPositif : 21.7 %\n",
      "Répartition dans le dataset de test (1472 tweets) : \n",
      " \tNégatif : 56.3 %\n",
      "\tPositif : 14.3 %\n",
      "Tweets : 14809 / N-grams : 9846\n",
      "Fitting 4 folds for each of 3 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   7 out of  12 | elapsed:  1.6min remaining:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of  12 | elapsed:  1.8min remaining:   36.7s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:  2.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les meilleurs paramètres pour rf sont {'n_estimators': 50}.\n",
      "Prédiction sur l'ensemble de test avec ces paramètres...\n",
      "Score 0.697690217391\n",
      "Répartition des prédictions : \n",
      " \tNégatif : 67.6 %\n",
      "\tPositif : 6.7 %\n",
      "\n",
      "Matrice de confusion (ligne: classe réelle, colonne: classe prédite):\n",
      "[[707 114   8]\n",
      " [197 233   3]\n",
      " [ 91  32  87]]\n",
      "Recall (négatif, neutre, positif) : 0.853, 0.538, 0.414\n",
      "Précision (négatif, neutre, positif) : 0.711, 0.615, 0.888\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators': [50, 60]}\n",
    "find_best_params(X, y, 'rf', params, cut=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Répartition dans le dataset de train (13337 tweets) : \n",
      " \tNégatif : 44.9 %\n",
      "\tPositif : 21.7 %\n",
      "Répartition dans le dataset de test (1472 tweets) : \n",
      " \tNégatif : 56.0 %\n",
      "\tPositif : 14.2 %\n",
      "Tweets : 14809 / N-grams : 9846\n",
      "Score 0.701766304348\n",
      "Répartition des prédictions : \n",
      " \tNégatif : 65.6 %\n",
      "\tPositif : 5.6 %\n",
      "\n",
      "Matrice de confusion (ligne: classe réelle, colonne: classe prédite):\n",
      "[[700 119   6]\n",
      " [167 264   7]\n",
      " [ 98  42  69]]\n",
      "Recall (négatif, neutre, positif) : 0.848, 0.603, 0.330\n",
      "Précision (négatif, neutre, positif) : 0.725, 0.621, 0.841\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=50, criterion='gini', max_depth=None, max_features='auto',\n",
    "                                     bootstrap=True, n_jobs=-1, verbose=0, class_weight='balanced')\n",
    "fit_predict(X, y, clf, cut=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
