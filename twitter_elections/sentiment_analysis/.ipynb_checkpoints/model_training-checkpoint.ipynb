{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import treetaggerwrapper\n",
    "import pymongo as pym\n",
    "import re\n",
    "import string\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mongo_to_df(collection, n_last_tweets=0, retweet=False):\n",
    "    tweets = collection.find(filter={'text':{'$exists':True}}, \n",
    "                             projection={'_id':False}).sort('$natural',-1).limit(n_last_tweets)\n",
    "    df = pd.DataFrame()\n",
    "    listTweets, listCandidats, listSentiments = [], [], []\n",
    "    \n",
    "    for t in tweets: \n",
    "        if not retweet: # filtrage des retweets\n",
    "            if 'rt @' in t['text']:\n",
    "                continue\n",
    "\n",
    "        if t['text']: # test si liste non vide\n",
    "            listTweets.append(t['text'])\n",
    "            try:\n",
    "                listCandidats.append(t['candidat'])\n",
    "            except:\n",
    "                listCandidats.append(None)\n",
    "            \n",
    "            try:\n",
    "                listSentiments.append(t['sentiment'])\n",
    "            except:\n",
    "                listSentiments.append(None)\n",
    "    \n",
    "    df['text'], df['candidat'], df['sentiment'] = listTweets, listCandidats, listSentiments\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_tweets(client, spellcheck, label_auto, retweet=True):\n",
    "    \n",
    "    if spellcheck:\n",
    "        collection = client.tweet.spellchecked\n",
    "        df_tweets = mongo_to_df(collection, n_last_tweets=0, retweet=retweet)\n",
    "        print('Correction orthographique activée.')\n",
    "        if not label_auto:\n",
    "            df_tweets = df_tweets[client.tweet.labelised.count():]\n",
    "    else:\n",
    "        collection = client.tweet.train\n",
    "        df_tweets = mongo_to_df(collection, n_last_tweets=0, retweet=retweet)\n",
    "        print('Correction orthographique desactivée.')\n",
    "        if label_auto:\n",
    "            # Base annotée automatiquement, sur la base des hashtags (uniquement des tweets positifs)\n",
    "            collection = client.tweet.labelised\n",
    "            df_tweets_auto = mongo_to_df(collection, n_last_tweets=0, retweet=retweet)\n",
    "            print('Ajout des tweets labélisés automatiquement...')\n",
    "            print('{} tweets ajoutés.'.format(df_tweets_auto['text'].count()))\n",
    "            df_tweets = pd.concat([df_tweets, df_tweets_auto], axis=0, ignore_index=True)\n",
    "        \n",
    "    print('\\n{} tweets au total récupérés pour entraînement, répartis comme suit :'.format(df_tweets['text'].count()))\n",
    "    print(df_tweets['sentiment'].value_counts())\n",
    "    print(df_tweets['candidat'].value_counts())\n",
    "        \n",
    "    return df_tweets\n",
    "\n",
    "\n",
    "def process_texts(list_of_texts, pos_tag_list, stop_words):\n",
    "    # Processing the tweets (POS tagging, lemmatization, spellchecking)\n",
    "    tagger = treetaggerwrapper.TreeTagger(TAGLANG='fr')\n",
    "    list_of_processed_texts = []\n",
    "    \n",
    "    for text in list_of_texts:\n",
    "        # Etape de filtrage\n",
    "        text = re.sub(r'\\w*…', '', text) # mot tronqué par Twitter\n",
    "        text = re.sub(r'(?:htt)\\S*', '', text) # retrait des liens http\n",
    "        text = re.sub(r'\\n', ' ', text) # retrait des sauts de ligne\n",
    "        text = re.sub(r'\\xad', '-', text)\n",
    "        text = re.sub(r'@\\w*', '', text) # retrait des mentions @ (ne détecte pas @XXX@...)\n",
    "        text = re.sub(r'\\.{3,}', '...', text) # ....... => points de suspension\n",
    "        text = re.sub(r'(?=\\.\\w)(\\.)', '. ', text) # remplacer un point entre deux mots 'A.B' par 'A. B'\n",
    "        text = re.sub(r'^rt.*: ', '', text) # retrait de la mention retweet\n",
    "        #text = re.sub(r'\\d', '', text) # retrait des chiffres\n",
    "        \n",
    "        tags = tagger.tag_text(text)\n",
    "        try:\n",
    "            tagged_text = ['{}|{}'.format(t.split('\\t')[1], t.split('\\t')[2]) for t in tags\n",
    "                           if (t.split('\\t')[2] not in stop_words\n",
    "                               and t.split('\\t')[1] in pos_tag_list)]\n",
    "        except:\n",
    "            tagged_text = ['ERREUR']\n",
    "        list_of_processed_texts.append(tagged_text)\n",
    "        \n",
    "    return list_of_processed_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_Xy(df_tweets, pos_tags_to_keep, stop_words, vocab=None, drop_dups=False, min_df=5, n_grams=(1,1)):\n",
    "    print('Tagging des tweets en cours...')\n",
    "    tweet_list = process_texts(df_tweets['text'], pos_tags_to_keep, stops)\n",
    "    print('TreeTagger a renvoye {} erreur(s).'.format(tweet_list.count('ERREUR')))\n",
    "    \n",
    "    # Building TF-IDF matrix\n",
    "    print('Creation de la matrice de features...')\n",
    "    vectorizer = TfidfVectorizer(strip_accents='unicode', analyzer='word', decode_error='strict',\n",
    "                                 lowercase=False, use_idf=False, norm=None, binary=False, vocabulary=vocab,\n",
    "                                 min_df=min_df, max_df=1.0, ngram_range=n_grams)\n",
    "    \n",
    "    mat = vectorizer.fit_transform([' '.join(tweet) for tweet in tweet_list])\n",
    "    del tweet_list\n",
    "\n",
    "    print('Taille du vocabulaire : {}'.format(len(vectorizer.vocabulary_)))\n",
    "    X = pd.DataFrame(mat.toarray())\n",
    "    del mat\n",
    "\n",
    "    # ajout colonnes features supplémentaires\n",
    "    X['#'] = np.array([t.count('#') / 2. for t in df_tweets['text']])\n",
    "    X['http'] = np.array([(t.count('http') / 2.) if t.count('http') > 1 else 0 for t in df_tweets['text']])\n",
    "    X['@'] = np.array([t.count('@') / 1. for t in df_tweets['text']])\n",
    "    X['n_car'] = np.array([np.log(len(t))/4 / 1. for t in df_tweets['text']])\n",
    "    X['n_words'] = np.array([np.log(len(t.split(' '))) / 2 for t in df_tweets['text']])\n",
    "    X[':'] = np.array([t.count(':') / 1. for t in df_tweets['text']])\n",
    "    X['!'] = np.array([t.count('!') / 1. for t in df_tweets['text']])\n",
    "    X['?'] = np.array([t.count('?') / 1. for t in df_tweets['text']])\n",
    "    X['\"'] = np.array([(t.count('\"') + t.count('»')) / 2. for t in df_tweets['text']])\n",
    "    \n",
    "    taille1 = X.shape[0]\n",
    "    taille2 = X.shape[0]\n",
    "    \n",
    "    if 'sentiment' in df_tweets: # si les labels sont fournis\n",
    "        X = pd.concat([X, df_tweets['sentiment']], axis=1)\n",
    "    else: # sinon\n",
    "        X['sentiment'] = np.zeros(taille1)\n",
    "\n",
    "    if drop_dups: # on ne retirera les doublons que pour l'ensemble d'entrainement\n",
    "        X.drop_duplicates(inplace=True)\n",
    "        taille2 = X.shape[0]\n",
    "        print('{} doublons retirés.'.format(taille1 - taille2))\n",
    "        \n",
    "    print('{} documents vectorisés.'.format(taille2))\n",
    "    print(X[:5])\n",
    "\n",
    "    return X.drop('sentiment', axis=1), X['sentiment'], vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_best_params(X, y, model, params_to_test, test_from=1, seed=1):\n",
    "    if model not in ['logistic', 'svc', 'nb', 'rf']:\n",
    "        print('Il faut choisir un modèle parmi logistic, svc, rf et nb.')\n",
    "        return\n",
    "    \n",
    "    # Building train & test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X[test_from:], y[test_from:],\n",
    "                                                        test_size = 0.2, random_state=seed)\n",
    "    X_train = pd.concat([X_train, X[:test_from]], axis=0)\n",
    "    y_train = pd.concat([y_train, y[:test_from]], axis=0)\n",
    "    \n",
    "    n_samples, vocabulaire = X.shape\n",
    "\n",
    "    print(\"Répartition dans le dataset de train ({} tweets) : \\n\".format(len(y_train)),\n",
    "          '\\tNégatif : {:.1f}'.format(len(np.extract(y_train == -1, y_train)) / len(y_train) * 100),\n",
    "          '%\\n\\tPositif : {:.1f}'.format(len(np.extract(y_train == 1, y_train)) / len(y_train) * 100), '%')\n",
    "    print(\"Répartition dans le dataset de test ({} tweets) : \\n\".format(len(y_test)),\n",
    "          '\\tNégatif : {:.1f}'.format(len(np.extract(y_test == -1, y_test)) / len(y_test) * 100),\n",
    "          '%\\n\\tPositif : {:.1f}'.format(len(np.extract(y_test == 1, y_test)) / len(y_test) * 100), '%')\n",
    "    print('Tweets : ' + str(n_samples) + ' / ' + 'N-grams : ' + str(vocabulaire))\n",
    "\n",
    "    # Choice of models\n",
    "    if model == 'logistic':\n",
    "        clf = LogisticRegression(max_iter=2000, class_weight='balanced', multi_class='ovr')\n",
    "    if model == 'svc':\n",
    "        clf = LinearSVC(class_weight='balanced')\n",
    "    if model == 'nb' :\n",
    "        clf = MultinomialNB()\n",
    "    if model == 'rf' :\n",
    "        clf = RandomForestClassifier(criterion='gini', max_depth=None, max_features='auto',\n",
    "                                     bootstrap=True, n_jobs=-1, verbose=0, class_weight='balanced_subsample')\n",
    "\n",
    "    gcv = GridSearchCV(clf, params_to_test, verbose=9, n_jobs=-1, cv=4, refit=True)\n",
    "    gcv.fit(X_train, y_train)\n",
    "    print('Les meilleurs paramètres pour {} sont {}.'.format(model, gcv.best_params_))\n",
    "    \n",
    "    # Fit & predict\n",
    "    print('Prédiction sur l\\'ensemble de test avec ces paramètres...')\n",
    "    y_pred = gcv.predict(X_test)\n",
    "\n",
    "    print('Score', np.sum(y_pred == y_test) / len(y_pred))\n",
    "    print('Répartition des prédictions : \\n',\n",
    "          '\\tNégatif : {:.1f}'.format(len(np.extract(y_pred == -1, y_pred)) / len(y_pred) * 100),\n",
    "          '%\\n\\tPositif : {:.1f}'.format(len(np.extract(y_pred == 1, y_pred)) / len(y_pred) * 100), '%')\n",
    "\n",
    "    # matrice de confusion\n",
    "    cf = confusion_matrix(y_test, y_pred)\n",
    "    recall = np.array([cf[i,i]/cf[i,:].sum() for i in range(3)])\n",
    "    precision = np.array([cf[i,i]/cf[:,i].sum() for i in range(3)])\n",
    "    print('\\nMatrice de confusion (ligne: classe réelle, colonne: classe prédite):')\n",
    "    print(cf)\n",
    "    print('Recall (négatif, neutre, positif) : {:.3f}, {:.3f}, {:.3f}'.format(recall[0], recall[1], recall[2]))\n",
    "    print('Précision (négatif, neutre, positif) : {:.3f}, {:.3f}, {:.3f}'.format(precision[0], precision[1], precision[2]))\n",
    "    print('Score F1 : {:.3f}'.format(np.mean(2 * recall * precision / (recall + precision))))\n",
    "    \n",
    "    return\n",
    "\n",
    "def fit_predict(X, y, clf, test_from=1, seed=1):\n",
    "    \n",
    "    # Building train & test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X[test_from:], y[test_from:],\n",
    "                                                        test_size = 0.15, random_state=seed)\n",
    "    X_train = pd.concat([X_train, X[:test_from]], axis=0)\n",
    "    y_train = pd.concat([y_train, y[:test_from]], axis=0)\n",
    "    \n",
    "    # mélange des lignes\n",
    "    n_samples, vocabulaire = X.shape\n",
    "\n",
    "    print(\"Répartition dans le dataset de train ({} tweets) : \\n\".format(len(y_train)),\n",
    "          '\\tNégatif : {:.1f}'.format(len(np.extract(y_train == -1, y_train)) / len(y_train) * 100),\n",
    "          '%\\n\\tPositif : {:.1f}'.format(len(np.extract(y_train == 1, y_train)) / len(y_train) * 100), '%')\n",
    "    print(\"Répartition dans le dataset de test ({} tweets) : \\n\".format(len(y_test)),\n",
    "          '\\tNégatif : {:.1f}'.format(len(np.extract(y_test == -1, y_test)) / len(y_test) * 100),\n",
    "          '%\\n\\tPositif : {:.1f}'.format(len(np.extract(y_test == 1, y_test)) / len(y_test) * 100), '%')\n",
    "    print('Tweets : ' + str(n_samples) + ' / ' + 'N-grams : ' + str(vocabulaire))\n",
    "\n",
    "    \n",
    "    # Fit & predict\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    print('Score', np.sum(y_pred == y_test) / len(y_pred))\n",
    "    print('Répartition des prédictions : \\n',\n",
    "          '\\tNégatif : {:.1f}'.format(len(np.extract(y_pred == -1, y_pred)) / len(y_pred) * 100),\n",
    "          '%\\n\\tPositif : {:.1f}'.format(len(np.extract(y_pred == 1, y_pred)) / len(y_pred) * 100), '%')\n",
    "\n",
    "    # matrice de confusion\n",
    "    cf = confusion_matrix(y_test, y_pred)\n",
    "    recall = np.array([cf[i,i]/cf[i,:].sum() for i in range(3)])\n",
    "    precision = np.array([cf[i,i]/cf[:,i].sum() for i in range(3)])\n",
    "    print('\\nMatrice de confusion (ligne: classe réelle, colonne: classe prédite):')\n",
    "    print(cf)\n",
    "    print('Recall (négatif, neutre, positif) : {:.3f}, {:.3f}, {:.3f}'.format(recall[0], recall[1], recall[2]))\n",
    "    print('Précision (négatif, neutre, positif) : {:.3f}, {:.3f}, {:.3f}'.format(precision[0], precision[1], precision[2]))\n",
    "    print('Score F1 : {:.3f}'.format(np.mean(2 * recall * precision / (recall + precision))))\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test du TreeTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output du tagger : ['mdr\\tNOM\\tmdr', 'lol\\tNOM\\tlol', ':\\tPUN\\t:', 'test\\tNOM\\ttest', 'nombre\\tNOM\\tnombre', '800\\tNUM\\t@card@', ',\\tPUN\\t,', '000\\tNUM\\t@card@', '€\\tNOM\\t€']\n",
      "Création des features : ['NOM|mdr', 'NOM|lol', 'PUN|:', 'NOM|test', 'NOM|nombre', 'NUM|@card@', 'PUN|,', 'NUM|@card@', 'NOM|€']\n"
     ]
    }
   ],
   "source": [
    "tagger = treetaggerwrapper.TreeTagger(TAGLANG='fr')\n",
    "tags = tagger.tag_text('mdr lol : test nombre 800,000 €')\n",
    "print('Output du tagger :', tags)\n",
    "tagged_text = ['{}|{}'.format(t.split('\\t')[1], t.split('\\t')[2]) for t in tags]\n",
    "print('Création des features :', tagged_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pour info : combien de tweets dans les différentes bases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18888 10001 8893\n"
     ]
    }
   ],
   "source": [
    "client = pym.MongoClient('localhost',27017)\n",
    "df_labelised = mongo_to_df(client.tweet.labelised, retweet=True)\n",
    "df_spell = mongo_to_df(client.tweet.spellchecked, retweet=True)\n",
    "df_train = mongo_to_df(client.tweet.train, retweet=True)\n",
    "print(df_spell.shape[0], df_train.shape[0], df_labelised.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chargement des tweets depuis Mongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correction orthographique desactivée.\n",
      "Ajout des tweets labélisés automatiquement...\n",
      "8893 tweets ajoutés.\n",
      "\n",
      "18894 tweets au total récupérés pour entraînement, répartis comme suit :\n",
      "-1.0    8572\n",
      " 0.0    6846\n",
      " 1.0    3476\n",
      "Name: sentiment, dtype: int64\n",
      "fillon       2709\n",
      "macron       2543\n",
      "le pen       2139\n",
      "hamon        1044\n",
      "melenchon     239\n",
      "mélenchon     219\n",
      "Name: candidat, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "client = pym.MongoClient('localhost',27017)\n",
    "df = load_tweets(client, spellcheck=False, label_auto=True, retweet=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choix des paramètres : POS tag à garder, dictionnaire de stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tagging des tweets en cours...\n",
      "TreeTagger a renvoye 0 erreur(s).\n",
      "Creation de la matrice de features...\n",
      "Taille du vocabulaire : 4884\n",
      "1628 doublons retirés.\n",
      "17266 documents vectorisés.\n",
      "     0    1    2    3    4    5    6    7    8    9    ...        #  http  \\\n",
      "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0    ...      0.5   0.0   \n",
      "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0    ...      0.0   0.0   \n",
      "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0    ...      0.0   0.0   \n",
      "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0    ...      0.5   0.0   \n",
      "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0    ...      0.0   0.0   \n",
      "\n",
      "     @     n_car   n_words    :    !    ?    \"  sentiment  \n",
      "0  0.0  1.228164  1.522261  1.0  0.0  0.0  0.0        1.0  \n",
      "1  0.0  0.972955  0.972955  0.0  0.0  0.0  0.0       -1.0  \n",
      "2  0.0  1.235411  1.609438  1.0  0.0  0.0  0.0       -1.0  \n",
      "3  1.0  1.235411  1.545521  1.0  2.0  0.0  0.0       -1.0  \n",
      "4  0.0  1.170533  1.242453  1.0  0.0  2.0  0.0       -1.0  \n",
      "\n",
      "[5 rows x 4894 columns]\n"
     ]
    }
   ],
   "source": [
    "# Choix des POS tags à conserver\n",
    "all_postags = ['ABR', 'ADJ', 'ADV', 'DET:ART', 'DET:POS', 'INT', 'KON', 'NAM', 'NOM', 'NUM', 'PRO',\n",
    "                   'PRO:DEM', 'PRO:IND', 'PRO:PER', 'PRO:POS', 'PRO:REL', 'PRP', 'PRP:det', 'PUN', 'PUN:cit',\n",
    "                   'SENT', 'SYM', 'VER:cond', 'VER:futu', 'VER:impe', 'VER:impf', 'VER:pper', 'VER:ppre',\n",
    "                   'VER:pres', 'VER:simp', 'VER:subi', 'VER:subp']\n",
    "\n",
    "pos_tags_to_keep = ['ADJ', 'ADV', 'NOM', 'NUM', 'PUN:cit', 'INT', 'DET:POS', 'PRO:POS', 'PRO:DEM',\n",
    "                    'VER:cond', 'VER:futu', 'VER:impe', 'VER:impf',\n",
    "                    'VER:pper', 'VER:ppre', 'VER:pres', 'VER:simp', 'VER:subi', 'VER:subp']\n",
    "\n",
    "# Choix des stop words\n",
    "stops = set(list('abcdefghijklmnopqrstuvwxyz'))\n",
    "X, y, voc = build_Xy(df, pos_tags_to_keep, stops, drop_dups=True, min_df=3, n_grams=(1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation des modeles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Essai avec Naive Bayes\n",
      "--------------------\n",
      "Répartition dans le dataset de train (14676 tweets) : \n",
      " \tNégatif : 48.6 %\n",
      "\tPositif : 19.4 %\n",
      "Répartition dans le dataset de test (2590 tweets) : \n",
      " \tNégatif : 49.3 %\n",
      "\tPositif : 19.7 %\n",
      "Tweets : 17266 / N-grams : 4893\n",
      "Score 0.713513513514\n",
      "Répartition des prédictions : \n",
      " \tNégatif : 51.4 %\n",
      "\tPositif : 16.3 %\n",
      "\n",
      "Matrice de confusion (ligne: classe réelle, colonne: classe prédite):\n",
      "[[977 241  58]\n",
      " [242 534  27]\n",
      " [111  63 337]]\n",
      "Recall (négatif, neutre, positif) : 0.766, 0.665, 0.659\n",
      "Précision (négatif, neutre, positif) : 0.735, 0.637, 0.799\n",
      "Score F1 : 0.708\n",
      "--------------------\n",
      "Essai avec Regression Logistique\n",
      "--------------------\n",
      "Répartition dans le dataset de train (14676 tweets) : \n",
      " \tNégatif : 48.6 %\n",
      "\tPositif : 19.4 %\n",
      "Répartition dans le dataset de test (2590 tweets) : \n",
      " \tNégatif : 49.3 %\n",
      "\tPositif : 19.7 %\n",
      "Tweets : 17266 / N-grams : 4893\n",
      "Score 0.743243243243\n",
      "Répartition des prédictions : \n",
      " \tNégatif : 49.9 %\n",
      "\tPositif : 16.1 %\n",
      "\n",
      "Matrice de confusion (ligne: classe réelle, colonne: classe prédite):\n",
      "[[996 242  38]\n",
      " [216 568  19]\n",
      " [ 81  69 361]]\n",
      "Recall (négatif, neutre, positif) : 0.781, 0.707, 0.706\n",
      "Précision (négatif, neutre, positif) : 0.770, 0.646, 0.864\n",
      "Score F1 : 0.743\n",
      "--------------------\n",
      "Essai avec LinearSVC\n",
      "--------------------\n",
      "Répartition dans le dataset de train (14676 tweets) : \n",
      " \tNégatif : 48.6 %\n",
      "\tPositif : 19.4 %\n",
      "Répartition dans le dataset de test (2590 tweets) : \n",
      " \tNégatif : 49.3 %\n",
      "\tPositif : 19.7 %\n",
      "Tweets : 17266 / N-grams : 4893\n",
      "Score 0.744787644788\n",
      "Répartition des prédictions : \n",
      " \tNégatif : 50.4 %\n",
      "\tPositif : 14.7 %\n",
      "\n",
      "Matrice de confusion (ligne: classe réelle, colonne: classe prédite):\n",
      "[[1001  248   27]\n",
      " [ 210  584    9]\n",
      " [  94   73  344]]\n",
      "Recall (négatif, neutre, positif) : 0.784, 0.727, 0.673\n",
      "Précision (négatif, neutre, positif) : 0.767, 0.645, 0.905\n",
      "Score F1 : 0.744\n"
     ]
    }
   ],
   "source": [
    "# Avec Naive Bayes\n",
    "print(20 * '-')\n",
    "print('Essai avec Naive Bayes')\n",
    "print(20 * '-')\n",
    "clf = MultinomialNB(alpha=1., fit_prior=True)\n",
    "fit_predict(X, y, clf, test_from=1)\n",
    "\n",
    "# Avec regression logistique\n",
    "print(20 * '-')\n",
    "print('Essai avec Regression Logistique')\n",
    "print(20 * '-')\n",
    "clf = LogisticRegression(C=.5, max_iter=2000, class_weight='balanced', multi_class='ovr',\n",
    "                        penalty='l2', dual=True)\n",
    "fit_predict(X, y, clf, test_from=1)\n",
    "\n",
    "# Avec linear SVC\n",
    "print(20 * '-')\n",
    "print('Essai avec LinearSVC')\n",
    "print(20 * '-')\n",
    "clf = LinearSVC(C=.02, class_weight='balanced')\n",
    "fit_predict(X, y, clf, test_from=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # Avec Naive Bayes\n",
    "# params = {'alpha': [1.]}\n",
    "# find_best_params(X, y, 'nb', params, test_from=1)\n",
    "\n",
    "# # Avec regression logistique\n",
    "# params = {'penalty':['l2'], 'dual': [True], 'C' : [.5]}\n",
    "# find_best_params(X, y, 'logistic', params, test_from=1)\n",
    "\n",
    "# # Avec linear SVC\n",
    "# params = {'C' : [.02, .1, 1.]}\n",
    "# find_best_params(X, y, 'svc', params, test_from=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sauvegarde du modèle et du vocabulaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trained_logistic_regression.pkl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sauvegarde du vocabulaire\n",
    "df_voc = pd.DataFrame.from_dict(voc, orient='index')\n",
    "df_voc.to_json('trained_dict.json')\n",
    "voca = pd.read_json('trained_dict.json').to_dict()[0]\n",
    "\n",
    "# Sauvegarde du modele\n",
    "clf = LogisticRegression(C=.5, max_iter=2000, class_weight='balanced', multi_class='ovr',\n",
    "                        penalty='l2', dual=True)\n",
    "clf.fit(X, y)\n",
    "joblib.dump(clf, 'trained_logistic_regression.pkl', protocol=2) # protocole compatible avec Python2\n",
    "\n",
    "# Choisir le modèle qui performe le mieux et ne pas oublier de changer le nom du fichier .pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test du chargement du modele (un score élevé indique le succès de l'opération)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice de confusion\n",
      "[[7103 1178  128]\n",
      " [ 879 4529   96]\n",
      " [ 364  336 2653]]\n",
      "\n",
      "Score : 0.827\n"
     ]
    }
   ],
   "source": [
    "model = joblib.load('trained_logistic_regression.pkl')\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "print('Matrice de confusion')\n",
    "print(confusion_matrix(y, y_pred))\n",
    "print('\\nScore : {:.3f}'.format(np.sum(y_pred==y) / len(y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
