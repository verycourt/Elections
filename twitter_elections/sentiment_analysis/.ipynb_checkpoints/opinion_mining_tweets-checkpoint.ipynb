{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Approche : mélanger analyse lexicale et par apprentissage.\n",
    "\n",
    "1. Analyse lexicale des tweets :\n",
    "    - POS tagging, lemmisation\n",
    "    - Traduction des mots en Anglais pour pouvoir utiliser Sentiwordnet et obtenir la polarité des mots\n",
    "\n",
    "2. Application d'un modèle d'apprentissage supervisé :\n",
    "    - HMM, SVM, etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Liste des POS tags français : http://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/data/french-tagset.html\n",
    "\n",
    "Etudier la possibilité d'ajout de lexiques d'opinion en Français : http://alpage.inria.fr/~sagot/wolf.html, http://sites.univ-provence.fr/wpsycle/outils_recherche/liwc/FrenchLIWCDictionary_V1_1.dic, http://sites.univ-provence.fr/~wpsycle/outils_recherche/outils_recherche.html#emotaix\n",
    "\n",
    "Voir l'approche compositionnelle : Moilanen 2007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "import treetaggerwrapper\n",
    "import time\n",
    "\n",
    "import pymongo as pym\n",
    "#import nltk.data\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "import stop_words\n",
    "#from nltk.stem import *\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mongo_to_df(collection, n_last_tweets=0, retweet=False):\n",
    "    tweets = collection.find(filter={'text':{'$exists':True}}, \n",
    "                             projection={'_id':False}).sort('$natural',-1).limit(n_last_tweets)\n",
    "    df = pd.DataFrame()\n",
    "    listTweets, listCandidats, listSentiments = [], [], []\n",
    "    \n",
    "    for t in tweets: \n",
    "        if not retweet: # filtrage des retweets\n",
    "            if 'rt @' in t['text']:\n",
    "                continue\n",
    "\n",
    "        if t['text']: # test si liste non vide\n",
    "            listTweets.append(t['text'])\n",
    "            try:\n",
    "                listCandidats.append(t['candidat'])\n",
    "            except:\n",
    "                listCandidats.append(None)\n",
    "            \n",
    "            try:\n",
    "                listSentiments.append(t['sentiment'])\n",
    "            except:\n",
    "                listSentiments.append(None)\n",
    "    \n",
    "    df['text'], df['candidat'], df['sentiment'] = listTweets, listCandidats, listSentiments\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_tweets(client, spellcheck=True, label_auto=True, retweet=True):\n",
    "    \n",
    "    if spellcheck:\n",
    "        collection = client.tweet.spellchecked\n",
    "        df_tweets = mongo_to_df(collection, n_last_tweets=0, retweet=retweet)\n",
    "        print('Correction orthographique activée.')\n",
    "        if not label_auto:\n",
    "            df_tweets = df_tweets[collection.count():]\n",
    "    else:\n",
    "        collection = client.tweet.train\n",
    "        df_tweets = mongo_to_df(collection, n_last_tweets=0, retweet=retweet)\n",
    "        print('Correction orthographique desactivée.')\n",
    "        if label_auto:\n",
    "            # Base annotée automatiquement, sur la base des hashtags (uniquement des tweets positifs)\n",
    "            collection = client.tweet.labelised\n",
    "            df_tweets_auto = mongo_to_df(collection, n_last_tweets=0, retweet=retweet)\n",
    "            print('Ajout des tweets labélisés automatiquement...')\n",
    "            print('{} tweets ajoutés.'.format(df_tweets_auto['text'].count()))\n",
    "            df_tweets = pd.concat([df_tweets, df_tweets_auto], axis=0, ignore_index=True)\n",
    "        \n",
    "    print('\\n{} tweets au total récupérés pour entraînement, répartis comme suit :'.format(df_tweets['text'].count()))\n",
    "    print(df_tweets['sentiment'].value_counts())\n",
    "    print(df_tweets['candidat'].value_counts())\n",
    "        \n",
    "    return df_tweets\n",
    "\n",
    "\n",
    "def process_texts(list_of_texts, pos_tag_list, stop_words):\n",
    "    # Processing the tweets (POS tagging, lemmatization, spellchecking)\n",
    "    tagger = treetaggerwrapper.TreeTagger(TAGLANG='fr')\n",
    "    list_of_processed_texts = []\n",
    "    \n",
    "    for text in list_of_texts:\n",
    "        # Etape de filtrage\n",
    "        text = re.sub(r'\\w*…', '', text) # mot tronqué par Twitter\n",
    "        text = re.sub(r'(?:htt)\\S*', '', text) # retrait des liens http\n",
    "        text = re.sub(r'\\n', ' ', text) # retrait des sauts de ligne\n",
    "        text = re.sub(r'\\xad', '-', text)\n",
    "        text = re.sub(r'@\\w*', '', text) # retrait des mentions @ (ne détecte pas @XXX@...)\n",
    "        text = re.sub(r'\\.{3,}', '...', text) # ....... => points de suspension\n",
    "        text = re.sub(r'(?=\\.\\w)(\\.)', '. ', text) # remplacer un point entre deux mots 'A.B' par 'A. B'\n",
    "        #text = re.sub(r'\\[a-zA-Z]*(?!\\S)', '', text) # retrait de ce qui n'est pas un mot\n",
    "        #text = re.sub(r'^rt.*: ', '', text) # retrait de la mention retweet\n",
    "        #text = re.sub(r'\\d', '', text) # retrait des chiffres\n",
    "        #text = re.sub(r',;!?\\/\\*(){}«»', ' ', text)\n",
    "        #text = re.sub('|'.join(['’', '_', '/', '-', '\\'', '“', '\\.']), ' ', text)\n",
    "        #text = re.sub('|'.join([elem + '\\'' for elem in 'cdjlmnst']), '', text) # apostrophes\n",
    "        \n",
    "        # TODO: (optionnel) retirer les # avant d'utiliser TreeTagger\n",
    "        # puis les remettre avec le tag HASH|\n",
    "        \n",
    "        # TODO: correction orthographique des tweets\n",
    "        \n",
    "        tags = tagger.tag_text(text)\n",
    "        \n",
    "        try:\n",
    "            tagged_text = ['{}|{}'.format(t.split('\\t')[1], t.split('\\t')[2]) for t in tags\n",
    "                           if (t.split('\\t')[2] not in stop_words\n",
    "                               and t.split('\\t')[1] in pos_tag_list)]\n",
    "        except:\n",
    "            tagged_text = ['ERREUR']\n",
    "        \n",
    "        # append les HASH|#...\n",
    "        # TODO: (optionnel) gérer les accents sur les mots\n",
    "        list_of_processed_texts.append(tagged_text)\n",
    "        \n",
    "    return list_of_processed_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_Xy(df_tweets, pos_tags_to_keep, stop_words):\n",
    "    # Tweet feature extraction\n",
    "    # TODO: faire des tests en ajoutant/retirant des features\n",
    "    hashtag = [t.count('#') for t in df_tweets['text']]\n",
    "    links = [t.count('http') for t in df_tweets['text']]\n",
    "    at = [t.count('@') for t in df_tweets['text']]\n",
    "    n_car = [np.log(len(t))/4 for t in df_tweets['text']]\n",
    "    n_words = [np.log(len(t.split(' ')))/2 for t in df_tweets['text']]\n",
    "    n_2points = [t.count(':') for t in df_tweets['text']]\n",
    "    n_exc = [t.count('!') for t in df_tweets['text']]\n",
    "    n_int = [t.count('?') for t in df_tweets['text']]\n",
    "\n",
    "    # d = t['text'].count('\"')\n",
    "    # g = t['text'].count('»')\n",
    "\n",
    "    print('Tagging des tweets en cours...')\n",
    "    tweet_list = process_texts(df_tweets['text'], pos_tags_to_keep, stop_words)\n",
    "\n",
    "    print('TreeTagger a renvoyé {} erreur(s).'.format(tweet_list.count('ERREUR')))\n",
    "\n",
    "    # Building feature matrix\n",
    "    print('\\nCréation de la matrice de features...')\n",
    "    vectorizer = TfidfVectorizer(strip_accents=None, analyzer='word', decode_error='strict',\n",
    "                                use_idf=False, norm=None, binary=False, min_df=1, max_df=1.0, ngram_range=(1,1))\n",
    "    tfidf = vectorizer.fit_transform([' '.join(tweet) for tweet in tweet_list])\n",
    "    X = pd.DataFrame(tfidf.toarray())\n",
    "\n",
    "    X_added_features = pd.DataFrame(data={'#': hashtag,\n",
    "                                          'http': links,\n",
    "                                          '@': at,\n",
    "                                          'n_car': n_car,\n",
    "                                          'n_words': n_words,\n",
    "                                          #':': n_2points,\n",
    "                                          #'!': n_exc,\n",
    "                                          #'?': n_int\n",
    "                                         })\n",
    "\n",
    "    X = pd.concat([X, X_added_features], axis=1)\n",
    "    print(X[:5])\n",
    "\n",
    "    y = df_tweets['sentiment']\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_best_params(X, y, model, params_to_test):\n",
    "    if model not in ['logistic', 'svc', 'nb']:\n",
    "        print('Il faut choisir un modèle parmi logistic, svc et nb.')\n",
    "        return\n",
    "    \n",
    "    # Building train & test sets\n",
    "    cut = 1\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X[:-cut], y[:-cut], test_size = 0.2)\n",
    "    X_train = pd.concat([X_train, X[-cut:]], axis=0)\n",
    "    y_train = pd.concat([y_train, y[-cut:]], axis=0)\n",
    "    n_samples, vocabulaire = X.shape\n",
    "\n",
    "    print(\"Répartition dans le dataset de train ({} tweets) : \\n\".format(len(y_train)),\n",
    "          \"\\tNégatif :\", np.abs(np.sum(y_train[y_train == -1])/len(y_train)),\n",
    "          \"%\\n\\tPositif :\", np.abs(np.sum(y_train[y_train == 1])/len(y_train)),\"%\")\n",
    "    print(\"Répartition dans le dataset de test ({} tweets) : \\n\".format(len(y_test)),\n",
    "          \"\\tNégatif :\", np.abs(np.sum(y_test[y_test == -1])/len(y_test)),\n",
    "          \"%\\n\\tPositif :\", np.abs(np.sum(y_test[y_test == 1])/len(y_test)),\"%\")\n",
    "    print('Tweets : ' + str(n_samples) + ' / ' + 'N-grams : ' + str(vocabulaire))\n",
    "\n",
    "    # Choice of models\n",
    "    if model == 'logistic':\n",
    "        clf = LogisticRegression(max_iter=2000, class_weight='balanced', multi_class='ovr')\n",
    "    if model == 'svc':\n",
    "        clf = LinearSVC(class_weight='balanced')\n",
    "    if model == 'nb' :\n",
    "        clf = MultinomialNB()\n",
    "\n",
    "    gcv = GridSearchCV(clf, params_to_test, verbose=9, n_jobs=-1, cv=4, refit=True)\n",
    "    gcv.fit(X_train, y_train)\n",
    "    print('Les meilleurs paramètres pour {} sont {}.'.format(model, gcv.best_params_))\n",
    "    \n",
    "    # Fit & predict\n",
    "    print('Prédiction sur l\\'ensemble de test avec ces paramètres...')\n",
    "    y_pred = gcv.predict(X_test)\n",
    "\n",
    "    print('Score', np.sum(y_pred == y_test) / len(y_pred))\n",
    "    print('Répartition des prédictions : \\n',\n",
    "          '\\tNégatif :', np.abs(np.sum(y_pred[y_pred == -1])/len(y_pred)),\n",
    "          '%\\n\\tPositif :', np.abs(np.sum(y_pred[y_pred == 1])/len(y_pred)), '%')\n",
    "\n",
    "    # matrice de confusion\n",
    "    cf = confusion_matrix(y_pred, y_test)\n",
    "    recall = [cf[i,i]/cf[i,:].sum() for i in range(3)]\n",
    "    precision = [cf[i,i]/cf[:,i].sum() for i in range(3)]\n",
    "    print('\\nMatrice de confusion (ligne: classe réelle, colonne: classe prédite):')\n",
    "    print(cf)\n",
    "    print('Recall (négatif, neutre, positif) : {:.3f}, {:.3f}, {:.3f}'.format(recall[0], recall[1], recall[2]))\n",
    "    print('Précision (négatif, neutre, positif) : {:.3f}, {:.3f}, {:.3f}'.format(precision[0], precision[1], precision[2]))\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test du TreeTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output du tagger : ['exemple\\tNOM\\texemple', 'de\\tPRP\\tde', 'texte\\tNOM\\ttexte', 'à\\tPRP\\tà', 'taguer\\tNOM\\ttaguer']\n",
      "Création des features : ['NOM|exemple', 'PRP|de', 'NOM|texte', 'PRP|à', 'NOM|taguer']\n"
     ]
    }
   ],
   "source": [
    "tagger = treetaggerwrapper.TreeTagger(TAGLANG='fr')\n",
    "tags = tagger.tag_text('exemple de texte à taguer')\n",
    "print('Output du tagger :', tags)\n",
    "tagged_text = ['{}|{}'.format(t.split('\\t')[1], t.split('\\t')[2]) for t in tags]\n",
    "print('Création des features :', tagged_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Echantillons de tweets dans la base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 10001 1718\n"
     ]
    }
   ],
   "source": [
    "client = pym.MongoClient('localhost',27017)\n",
    "df_labelised = mongo_to_df(client.tweet.labelised, retweet=True)\n",
    "df_spell = mongo_to_df(client.tweet.spellchecked, retweet=True)\n",
    "df_train = mongo_to_df(client.tweet.train, retweet=True)\n",
    "print(df_spell.shape[0], df_train.shape[0], df_labelised.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(0, 20):\n",
    "    print(df_spell['text'][i])\n",
    "    print(2*'-')\n",
    "    print(df_train['text'][i])\n",
    "    print(10*'-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement des tweets depuis Mongo et création des features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correction orthographique desactivée.\n",
      "Ajout des tweets labélisés automatiquement...\n",
      "1715 tweets ajoutés.\n",
      "\n",
      "9260 tweets au total récupérés pour entraînement, répartis comme suit :\n",
      "-1.0    3742\n",
      " 0.0    2844\n",
      " 1.0    2674\n",
      "Name: sentiment, dtype: int64\n",
      "macron       498\n",
      "fillon       498\n",
      "le pen       464\n",
      "melenchon    140\n",
      "hamon        115\n",
      "Name: candidat, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Choix de la base à utiliser\n",
    "client = pym.MongoClient('localhost',27017)\n",
    "df = load_tweets(client, spellcheck=False, label_auto=True, retweet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tagging des tweets en cours...\n",
      "TreeTagger a renvoyé 0 erreur(s).\n",
      "\n",
      "Création de la matrice de features...\n",
      "     0    1    2    3    4    5    6    7    8    9    ...     9996  9997  \\\n",
      "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0    ...      0.0   0.0   \n",
      "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0    ...      0.0   0.0   \n",
      "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0    ...      0.0   0.0   \n",
      "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0    ...      0.0   0.0   \n",
      "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0    ...      0.0   0.0   \n",
      "\n",
      "   9998  9999  10000  #  @  http     n_car   n_words  \n",
      "0   0.0   0.0    0.0  1  0     1  1.228164  1.522261  \n",
      "1   0.0   0.0    0.0  0  0     0  0.972955  0.972955  \n",
      "2   0.0   0.0    0.0  0  0     1  1.235411  1.609438  \n",
      "3   0.0   0.0    0.0  1  1     1  1.235411  1.545521  \n",
      "4   0.0   0.0    0.0  0  0     1  1.170533  1.242453  \n",
      "\n",
      "[5 rows x 10006 columns]\n"
     ]
    }
   ],
   "source": [
    "# Choix des POS tags à conserver\n",
    "all_postags = ['ABR', 'ADJ', 'ADV', 'DET:ART', 'DET:POS', 'INT', 'KON', 'NAM', 'NOM', 'NUM', 'PRO',\n",
    "                   'PRO:DEM', 'PRO:IND', 'PRO:PER', 'PRO:POS', 'PRO:REL', 'PRP', 'PRP:det', 'PUN', 'PUN:cit',\n",
    "                   'SENT', 'SYM', 'VER:cond', 'VER:futu', 'VER:impe', 'VER:impf', 'VER:pper', 'VER:ppre',\n",
    "                   'VER:pres', 'VER:simp', 'VER:subi', 'VER:subp']\n",
    "\n",
    "pos_tags_to_keep = ['ADJ', 'ADV', 'NOM', 'PRO:POS', 'PRO:DEM', 'VER:cond', 'VER:futu', 'VER:impe', 'VER:impf',\n",
    "                'VER:pper', 'VER:ppre', 'VER:pres', 'VER:simp', 'VER:subi', 'VER:subp']\n",
    "\n",
    "# Choix des stop words\n",
    "# stops = set(['rt','ds','qd','ss','ns','vs','nn','amp','gt','gd','gds','tt','pr','ac','mm', 'qu',\n",
    "#             '``', 'ca', 'mdr', 'lol', 'dsl', 'cad']\n",
    "#             + list('@ن%£€‘:&;')\n",
    "#             + list('abcdefghijklmnopqrstuvwxyzà')\n",
    "#            + stop_words.get_stop_words(language='fr')\n",
    "#            + stopwords.words('french')\n",
    "#            )\n",
    "stops = set(list('abcdefghijklmnopqrstuvwxyz'))\n",
    "# TODO: améliorer la liste de stop words\n",
    "    \n",
    "X, y = build_Xy(df, pos_tags_to_keep, stops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test avec la regression logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Répartition dans le dataset de train (7408 tweets) : \n",
      " \tNégatif : 0.403347732181 %\n",
      "\tPositif : 0.287257019438 %\n",
      "Répartition dans le dataset de test (1852 tweets) : \n",
      " \tNégatif : 0.407127429806 %\n",
      "\tPositif : 0.294816414687 %\n",
      "Tweets : 9260 / N-grams : 10006\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   4 | elapsed:   20.1s remaining:   20.1s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   27.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   27.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les meilleurs paramètres pour logistic sont {'penalty': 'l2', 'C': 0.5, 'dual': True}.\n",
      "Prédiction sur l'ensemble de test avec ces paramètres...\n",
      "Score 0.686825053996\n",
      "Répartition des prédictions : \n",
      " \tNégatif : 0.42494600432 %\n",
      "\tPositif : 0.224622030238 %\n",
      "\n",
      "Matrice de confusion (ligne: classe réelle, colonne: classe prédite):\n",
      "[[527 151 109]\n",
      " [195 381  73]\n",
      " [ 32  20 364]]\n",
      "Recall (négatif, neutre, positif) : 0.670, 0.587, 0.875\n",
      "Précision (négatif, neutre, positif) : 0.699, 0.690, 0.667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 0.5, 'dual': True, 'penalty': 'l2'}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'penalty':['l2'], 'dual': [True], 'C' : [.5]}\n",
    "find_best_params(X, y, 'logistic', params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test avec le LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Répartition dans le dataset de train (7751 tweets) : \n",
      " \tNégatif : 0.387433879499 %\n",
      "\tPositif : 0.31931363695 %\n",
      "Répartition dans le dataset de test (1509 tweets) : \n",
      " \tNégatif : 0.489728296885 %\n",
      "\tPositif : 0.131875414182 %\n",
      "Tweets : 9260 / N-grams : 10006\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   4 | elapsed:   19.6s remaining:   19.6s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   27.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   27.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les meilleurs paramètres pour svc sont {'C': 0.02}.\n",
      "\n",
      "Score 0.643472498343\n",
      "Répartition des prédictions : \n",
      " \tNégatif : 0.560636182903 %\n",
      "\tPositif : 0.037773359841 %\n",
      "\n",
      "Matrice de confusion (ligne: classe réelle, colonne: classe prédite):\n",
      "[[569 178  99]\n",
      " [150 379  77]\n",
      " [ 20  14  23]]\n",
      "Recall (négatif, neutre, positif) : 0.673, 0.625, 0.404\n",
      "Précision (négatif, neutre, positif) : 0.770, 0.664, 0.116\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 0.02}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'C' : [.02]}\n",
    "find_best_params(X, y, 'svc', params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test avec Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Répartition dans le dataset de train (7751 tweets) : \n",
      " \tNégatif : 0.384337504838 %\n",
      "\tPositif : 0.321893949168 %\n",
      "Répartition dans le dataset de test (1509 tweets) : \n",
      " \tNégatif : 0.50563286945 %\n",
      "\tPositif : 0.118621603711 %\n",
      "Tweets : 9260 / N-grams : 10006\n",
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  11 out of  16 | elapsed:   42.0s remaining:   19.0s\n",
      "[Parallel(n_jobs=-1)]: Done  13 out of  16 | elapsed:   46.4s remaining:   10.6s\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  16 | elapsed:   51.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les meilleurs paramètres pour nb sont {'alpha': 1.0}.\n",
      "\n",
      "Score 0.60901259112\n",
      "Répartition des prédictions : \n",
      " \tNégatif : 0.557322730285 %\n",
      "\tPositif : 0.102054340623 %\n",
      "\n",
      "Matrice de confusion (ligne: classe réelle, colonne: classe prédite):\n",
      "[[549 189 103]\n",
      " [144 332  38]\n",
      " [ 70  46  38]]\n",
      "Recall (négatif, neutre, positif) : 0.653, 0.646, 0.247\n",
      "Précision (négatif, neutre, positif) : 0.720, 0.586, 0.212\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'alpha': 1.0}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'alpha': [.5, 1., 1.5, 2.]}\n",
    "find_best_params(X, y, 'nb', params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
