{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To do\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import Imputer, StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, f1_score, r2_score\n",
    "from sklearn.metrics import auc, confusion_matrix, make_scorer\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille initiale du DF : (36919, 81)\n",
      "Taille du DF après retrait des colonnes inutiles : (36919, 69)\n"
     ]
    }
   ],
   "source": [
    "raw = pd.read_excel('data/dataframe_elections.xlsx')\n",
    "print('Taille initiale du DF :', raw.shape)\n",
    "\n",
    "# Données d'identification\n",
    "id_list = ['an', 'dep', 'circo', 'code', 'nom', 'prenom', 'nuance', 'nuance_groupe', 'bloc',\n",
    "           'taux_vote_leg', 'second_tour']\n",
    "df_id = raw[id_list]\n",
    "\n",
    "# drop colonnes\n",
    "drop_list = ['dep', 'circo', 'code', 'inscrits', 'circo_parti', 'circo_nuance',\n",
    "             'nom', 'prenom', 'etiquette', 'nuance', 'voix', 'second_tour']\n",
    "raw = raw.drop(drop_list, axis=1)\n",
    "\n",
    "print('Taille du DF après retrait des colonnes inutiles :', raw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def generate_df(raw_data, keep_list, penalty=.8, filter_div=False):\n",
    "    # à garder obligatoirement pour identifier les lignes et créer les labels\n",
    "    keep_list.extend(['an', 'c_dep', 'nuance_groupe', 'p_inscrits', 'p_exprimes'])\n",
    "\n",
    "    df = raw_data.drop([col for col in raw_data.columns if col not in keep_list], axis=1)\n",
    "    #print(df.columns)\n",
    "\n",
    "    # Gestion des NaN au niveau du score du candidat aux législatives précédentes\n",
    "    years = [2002, 2007, 2012, 2017]\n",
    "    partis = ['EXG', 'COM', 'FI', 'DVG', 'ECO', 'SOC', 'RDG', 'MDM',\n",
    "              'UDI', 'DVD', 'LR', 'DLF', 'FN', 'EXD', 'REG', 'DIV']\n",
    "    \n",
    "    # TODO : POUR LES CANDIDATS \"EN MARCHE\", PAR QUOI REMPLIR LE SCORE DES CANDIDATS A LA PREC LEG ?\n",
    "    \n",
    "    if 'score_candidat_prec_leg_ins' in keep_list:\n",
    "        for parti in partis:\n",
    "            #print('\\nRemplissage des valeurs manquantes pour {} :'.format(parti))\n",
    "            for year in years:\n",
    "                mask = (df['an']==year) & (df['nuance_groupe']==parti)\n",
    "                mask_2 = (df['an']==year - 5) & (df['nuance_groupe']==parti)\n",
    "                mean = np.mean(df['p_inscrits'][mask_2]) * penalty # moyenne des voix du parti 5 ans avant (% d'inscrits)\n",
    "                df.loc[mask, 'score_candidat_prec_leg_ins'] = df['score_candidat_prec_leg_ins'][mask].fillna(value=mean)\n",
    "                #print('La moyenne du parti en {} est {:.2f}%'.format(year - 5, mean * 100))\n",
    "\n",
    "        mean = np.mean(df.p_inscrits) * penalty\n",
    "        df.score_candidat_prec_leg_ins = df.score_candidat_prec_leg_ins.fillna(value=mean)\n",
    "        \n",
    "    if 'score_candidat_prec_leg_expr' in keep_list:\n",
    "        for parti in partis:\n",
    "            #print('\\nRemplissage des valeurs manquantes pour {} :'.format(parti))\n",
    "            for year in years:\n",
    "                mask = (df['an']==year) & (df['nuance_groupe']==parti)\n",
    "                mask_2 = (df['an']==year - 5) & (df['nuance_groupe']==parti)\n",
    "                mean = np.mean(df['p_exprimes'][mask_2]) * penalty # moyenne des voix du parti 5 ans avant (% exprimés)\n",
    "                df.loc[mask, 'score_candidat_prec_leg_expr'] = df['score_candidat_prec_leg_expr'][mask].fillna(value=mean)\n",
    "                #print('La moyenne du parti en {} est {:.2f}%'.format(year - 5, mean * 100))\n",
    "\n",
    "        mean = np.mean(df.p_exprimes)\n",
    "        df.score_candidat_prec_leg_expr = df.score_candidat_prec_leg_expr.fillna(value=mean)\n",
    "\n",
    "    # Gestion des NaN : Autres variables. Remplacement des valeurs manquantes par la moyenne nationale\n",
    "    features_a_completer = ['chom_tot', 'chom_jeunes', 'chom_adultes', 'chom_seniors',\n",
    "                           'p_agri', 'p_commercants', 'p_cadres', 'p_intermed', 'p_employes',\n",
    "                           'p_ouvriers', 'd_brevet', 'd_bep', 'd_bac', 'd_sup']\n",
    "    for feature in features_a_completer:\n",
    "        if feature in keep_list:\n",
    "            #print('\\nRemplissage des valeurs manquantes pour {} :'.format(feature))\n",
    "            for year in years:\n",
    "                mask = (df['an']==year)\n",
    "                mean = np.mean(df[feature][mask])\n",
    "                #print('La moyenne de la feature pour {} est {:.2f}%'.format(year, mean * 100))\n",
    "                df.loc[mask, feature] = df[feature][mask].fillna(value=mean)\n",
    "\n",
    "    # Catégorisation\n",
    "    if 'score_candidat_prec_leg_cat' in keep_list:\n",
    "        if 'score_candidat_prec_leg_expr' in keep_list:\n",
    "            df['score_candidat_prec_leg_cat'] = pd.cut(df['score_candidat_prec_leg_expr'],\n",
    "                                                       bins=[-1, -.01, .05, .1, .15, .25, 1],\n",
    "                                                       labels=['N/A', 'A', 'B', 'C', 'D', 'E'])\n",
    "        elif 'score_candidat_prec_leg_ins' in keep_list:\n",
    "            df['score_candidat_prec_leg_cat'] = pd.cut(df['score_candidat_prec_leg_ins'],\n",
    "                                                       bins=[-1, -.01, .05, .1, .15, .25, 1],\n",
    "                                                       labels=['N/A', 'A', 'B', 'C', 'D', 'E'])\n",
    "\n",
    "    df = df[df.an > 1997]\n",
    "    df = df[df.c_dep!=99] # Retrait des Français de l'Etranger\n",
    "    if filter_div: # On retire les candidats \"Divers\" (pour l'entraînement ET la prédiction)\n",
    "        df = df[df.nuance_groupe!='DIV']\n",
    "    \n",
    "    \n",
    "    df = df.drop(['c_dep', 'nuance_groupe'], axis=1)\n",
    "    \n",
    "    print('Format du dataframe :', df.shape)\n",
    "    print(df.isnull().sum())\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_val_splits(df, year_for_validation, target, scaler=MinMaxScaler()):\n",
    "    # Liste des variables dummies et binaires pour les exclure de la normalisation\n",
    "    dummies_list = ['bloc', 'sexe', 'an', 'p_inscrits', 'p_exprimes', 'dep', 'circo',\n",
    "                    'geo_frontalier', 'geo_dom', 'geo_idf',\n",
    "                    'circo_nuance_groupe', 'circo_bloc', 'nuance_groupe',\n",
    "                    'circo_nuance_groupe_pres', 'circo_pres_meme_nuance', 'circo_meme_nuance_president',\n",
    "                    'circo_leg_meme_nuance',\n",
    "                    'depute_sortant', 'ancien_depute', 'au_gouvernement', 'ancien_ministre', 'membre_majorite',\n",
    "                    #'nb_candidats_meme_bloc', 'nb_candidats_circo',\n",
    "                    'score_candidat_prec_leg_cat',\n",
    "                    'score_candidat_prec_leg_expr', 'score_candidat_prec_leg_ins',\n",
    "                    #'nb_acces_second_tour'\n",
    "                   ]\n",
    "    scale_list = [col for col in df.columns if col not in dummies_list]\n",
    "\n",
    "    df = pd.get_dummies(df, drop_first=True)\n",
    "    \n",
    "    drop_list = ['an', 'p_inscrits', 'p_exprimes']\n",
    "    df_train = df[(df.an != 2017) & (df.an != year_for_validation)].dropna(how='any')\n",
    "    y_train = df_train[target]\n",
    "    X_train = df_train.drop(drop_list, axis=1)\n",
    "    \n",
    "    if year_for_validation != 2017:\n",
    "        df_val = df[df.an == year_for_validation].dropna(how='any')\n",
    "    else: # on ne drop pas car pour 2017 toutes les valeurs cibles sont des N/A\n",
    "        df_val = df[df.an == year_for_validation]\n",
    "    \n",
    "    y_val = df_val[target]\n",
    "    X_val = df_val.drop(drop_list, axis=1)\n",
    "    \n",
    "    # Normalisation du dataframe\n",
    "    if scaler:\n",
    "        print('Variables à normaliser', scale_list)\n",
    "        X_train[scale_list] = scaler.fit_transform(X_train[scale_list])\n",
    "        X_val[scale_list] = scaler.transform(X_val[scale_list])\n",
    "\n",
    "    print('Format des ensembles de train et de validation :')\n",
    "    print(X_train.shape, X_val.shape)\n",
    "    \n",
    "    return X_train, X_val, y_train, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_classif(y_pred, y_val, id_val, target, strategy):\n",
    "    from scipy.stats import rankdata\n",
    "    \n",
    "    res = pd.concat([id_val, pd.DataFrame(y_val)], axis=1, join='inner')\n",
    "    res['prediction'] = y_pred\n",
    "    res['classement'] = 0\n",
    "    res['qualif'] = 'N'\n",
    "    \n",
    "    for circo in set(res.code):\n",
    "        # classement des candidats par circonscription\n",
    "        res.loc[res.code==circo, 'classement'] = rankdata(-res.prediction[res.code==circo], method='ordinal')\n",
    "        \n",
    "        # normalisation des votes pour que la somme soit égale à 100%\n",
    "        res.loc[res.code==circo, 'prediction'] /= np.sum(res.loc[res.code==circo, 'prediction'])\n",
    "        \n",
    "        if target=='p_exprimes':\n",
    "            taux_E = 1\n",
    "            taux_O = np.float(res.loc[(res.code==circo) & (res.classement==1), 'taux_vote_leg'])\n",
    "        elif target=='p_inscrits':\n",
    "            taux_E = 1 / np.float(res.loc[(res.code==circo) & (res.classement==1), 'taux_vote_leg'])\n",
    "            taux_O = 1\n",
    "            \n",
    "        # simulation des qualifiés pour le second tour\n",
    "        i = 1\n",
    "        q = 0\n",
    "        while True:\n",
    "            #print(res.loc[(res.code==circo) & (res.classement==i), 'prediction'].values)\n",
    "            if (res.loc[(res.code==circo) & (res.classement==i), 'prediction'].values) * taux_E >= .5:\n",
    "                res.loc[(res.code==circo) & (res.classement==i), 'qualif'] = 'E'\n",
    "                if strategy == 'O':\n",
    "                    q += 1\n",
    "                elif strategy == 'E':\n",
    "                    break\n",
    "            elif (res.loc[(res.code==circo) & (res.classement==i), 'prediction'].values) * taux_O >= .125:\n",
    "                res.loc[(res.code==circo) & (res.classement==i), 'qualif'] = 'O'\n",
    "                q += 1\n",
    "            elif q < 2:\n",
    "                res.loc[(res.code==circo) & (res.classement==i), 'qualif'] = 'O'\n",
    "                q += 1\n",
    "            else:\n",
    "                break\n",
    "\n",
    "            i += 1\n",
    "        \n",
    "    res['ecart'] = res['prediction'] - res[target]\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def analyze_predictions(df_predictions, target):\n",
    "    n = df_predictions.shape[0]\n",
    "    print('Prédictions pour {} candidats.'.format(n))\n",
    "\n",
    "    ecarts_absolus = abs(df_predictions.ecart)\n",
    "    max_ecart = np.max(ecarts_absolus)\n",
    "    grid = np.arange(max_ecart, step=.01)\n",
    "    ecarts_grid = []\n",
    "\n",
    "    for point in grid:\n",
    "        ecarts_grid.append(np.sum(ecarts_absolus < point))\n",
    "\n",
    "    print('La MAE est : {:.2f}%'.format(\n",
    "            mean_absolute_error(df_predictions[target], df_predictions.prediction) * 100))\n",
    "    print('La plus grosse erreur est : {:.2f}%'.format(max_ecart * 100))\n",
    "    print('Le score r2 est : {:.2f}'.format(r2_score(df_predictions[target], df_predictions.prediction)))\n",
    "\n",
    "    point_list = [.01, .02, .05, .1]\n",
    "    ecart_list = [np.sum(ecarts_absolus < point) for point in point_list]\n",
    "\n",
    "    plt.figure(1, figsize=(13, 3))\n",
    "    plt.subplot(121)\n",
    "    plt.plot(grid, ecarts_grid)\n",
    "    for i in range(len(point_list)):\n",
    "        plt.plot(point_list[i], ecart_list[i], 'ro')\n",
    "        plt.text(point_list[i]+.005, ecart_list[i]-400, '{:.2f}%'.format(ecart_list[i]/n))\n",
    "\n",
    "    plt.title('Nb d\\'obs en dessous d\\'un seuil d\\'erreur')\n",
    "    plt.xlabel('Seuils d\\'erreur')\n",
    "\n",
    "    plt.subplot(122)\n",
    "    plt.hist(df_predictions['ecart'], bins=50)\n",
    "    plt.title('Répartition globale des erreurs')\n",
    "\n",
    "    # comparaison de la distribution des erreurs, parti par parti\n",
    "    from scipy.stats import gaussian_kde\n",
    "    plt.figure(2, figsize=(15,4))\n",
    "    x_grid = np.arange(min(df_predictions['ecart']), max(df_predictions['ecart']), step=.01)\n",
    "    \n",
    "    nuances = {'FI': 'red','ECO': 'green', 'SOC': 'pink', 'RDG': 'grey', 'MDM': 'orange', 'UDI': 'yellow',\n",
    "               'LR': 'blue', 'DLF': 'darkblue', 'FN': 'black', 'REG': 'teal'}\n",
    "    for nuance in nuances:\n",
    "        n_pred = df_predictions[(df_predictions['nuance_groupe']==nuance)\n",
    "                                & ((df_predictions['qualif']=='E')\n",
    "                               | (df_predictions['qualif']=='O'))].shape[0]\n",
    "        n_reel = df_predictions[(df_predictions['nuance_groupe']==nuance)\n",
    "                                & ((df_predictions['second_tour']=='E')\n",
    "                               | (df_predictions['second_tour']=='O'))].shape[0]\n",
    "        print('{}: {} prédits | Réel {}'.format(nuance, n_pred, n_reel))\n",
    "        try: # cas où le parti n'est pas représenté à l'élection prédite\n",
    "            pdf = gaussian_kde(df_predictions['ecart'][df_predictions['nuance_groupe']==nuance],\n",
    "                               bw_method=.9).evaluate(x_grid)\n",
    "            plt.plot(x_grid, pdf, color=nuances[nuance], label=nuance, lw=2)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    plt.title('Répartition des erreurs selon le parti')\n",
    "    plt.legend(loc='best')\n",
    "\n",
    "    n_correct = np.sum(df_predictions.second_tour == df_predictions.qualif)\n",
    "    print('\\n{} prédictions correctes sur {} (soit {:.1f}%)'.format(n_correct, n, 100 * n_correct / n))\n",
    "\n",
    "    print('\\nMatrice de confusion. En colonne les classes prédites, en ligne les classes réelles.')\n",
    "    cm = confusion_matrix(df_predictions.second_tour, df_predictions.qualif, labels=['E', 'O', 'N'])\n",
    "    print(cm)\n",
    "\n",
    "    f1_E = f1_score(df_predictions.second_tour, df_predictions.qualif, labels='E', average='micro')\n",
    "    print('Score F1 pour la classe E : {:.1f}%'.format(f1_E * 100))\n",
    "    f1_O = f1_score(df_predictions.second_tour, df_predictions.qualif, labels='O', average='micro')\n",
    "    print('Score F1 pour la classe O : {:.1f}%'.format(f1_O * 100))\n",
    "    f1_N = f1_score(df_predictions.second_tour, df_predictions.qualif, labels='N', average='micro')\n",
    "    print('Score F1 pour la classe N : {:.1f}%'.format(f1_N * 100))\n",
    "    plt.show()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choix des paramètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sélection des features\n",
    "keep_list = [#'geo_frontalier', 'geo_dom', 'geo_idf',\n",
    "    'part_impose', 'chom_tot',\n",
    "    'chom_jeunes', 'chom_adultes', 'chom_seniors',\n",
    "    'revenus_q1',\n",
    "    'revenus_med',\n",
    "    'revenus_q3',\n",
    "    #'ecart_revenus',\n",
    "    'p_agri', 'p_commercants', 'p_cadres', 'p_intermed', 'p_employes',\n",
    "    'p_ouvriers', 'd_brevet', 'd_bep', 'd_bac', 'd_sup',\n",
    "    #'taux_vote_pres',\n",
    "    'sexe',\n",
    "    'circo_leg_meme_nuance', 'circo_pres_meme_nuance',\n",
    "    #'circo_meme_nuance_president',\n",
    "    'nb_candidats_meme_bloc',\n",
    "    'nb_candidats_circo',\n",
    "    'score_nuance_groupe_pres', 'score_bloc_pres',\n",
    "    #'score_pres_exg', 'score_pres_g', 'score_pres_c', 'score_pres_d', 'score_pres_exd', 'score_pres_div',\n",
    "    #'score_candidat_prec_leg_ins',\n",
    "    #'score_candidat_prec_leg_expr',\n",
    "    #'score_candidat_prec_leg_cat',\n",
    "    #'score_nuance_groupe_prec_leg', #(un peu mauvais)\n",
    "    #'score_bloc_prec_leg', #(mauvais pour le score)\n",
    "    #'nuance_groupe',\n",
    "    'depute_sortant', 'ancien_depute', 'au_gouvernement', 'ancien_ministre', 'membre_majorite',\n",
    "    'nb_acces_second_tour'\n",
    "]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "#scaler = StandardScaler()\n",
    "\n",
    "# Prédire les score en % des voix exprimées ou % des inscrits sur les listes électorales\n",
    "target_values = 'p_exprimes' # 'p_inscrits'\n",
    "target_year = 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Format du dataframe : (30205, 34)\n",
      "an                             0\n",
      "part_impose                    0\n",
      "revenus_q1                     0\n",
      "revenus_med                    0\n",
      "revenus_q3                     0\n",
      "chom_tot                       0\n",
      "chom_jeunes                    0\n",
      "chom_adultes                   0\n",
      "chom_seniors                   0\n",
      "p_agri                         0\n",
      "p_commercants                  0\n",
      "p_cadres                       0\n",
      "p_intermed                     0\n",
      "p_employes                     0\n",
      "p_ouvriers                     0\n",
      "d_brevet                       0\n",
      "d_bep                          0\n",
      "d_bac                          0\n",
      "d_sup                          0\n",
      "circo_leg_meme_nuance          0\n",
      "circo_pres_meme_nuance         0\n",
      "score_nuance_groupe_pres       0\n",
      "score_bloc_pres                0\n",
      "depute_sortant                 0\n",
      "ancien_depute                  0\n",
      "au_gouvernement                0\n",
      "ancien_ministre                0\n",
      "membre_majorite                0\n",
      "nb_acces_second_tour           0\n",
      "nb_candidats_meme_bloc         0\n",
      "nb_candidats_circo             0\n",
      "sexe                           0\n",
      "p_inscrits                  7699\n",
      "p_exprimes                  7699\n",
      "dtype: int64\n",
      "Variables à normaliser ['part_impose', 'revenus_q1', 'revenus_med', 'revenus_q3', 'chom_tot', 'chom_jeunes', 'chom_adultes', 'chom_seniors', 'p_agri', 'p_commercants', 'p_cadres', 'p_intermed', 'p_employes', 'p_ouvriers', 'd_brevet', 'd_bep', 'd_bac', 'd_sup', 'score_nuance_groupe_pres', 'score_bloc_pres', 'nb_acces_second_tour', 'nb_candidats_meme_bloc', 'nb_candidats_circo']\n",
      "Format des ensembles de train et de validation :\n",
      "(22506, 31) (7699, 31)\n"
     ]
    }
   ],
   "source": [
    "# Taux par lequel on multiplie les score à la législative précédente qui étaient à la base des N/A\n",
    "df = generate_df(raw, keep_list, penalty=.9, filter_div=False)\n",
    "X_train, X_val, y_train, y_val = train_val_splits(df, target_year, target_values, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['part_impose', 'revenus_q1', 'revenus_med', 'revenus_q3', 'chom_tot',\n",
       "       'chom_jeunes', 'chom_adultes', 'chom_seniors', 'p_agri',\n",
       "       'p_commercants', 'p_cadres', 'p_intermed', 'p_employes', 'p_ouvriers',\n",
       "       'd_brevet', 'd_bep', 'd_bac', 'd_sup', 'circo_leg_meme_nuance',\n",
       "       'circo_pres_meme_nuance', 'score_nuance_groupe_pres', 'score_bloc_pres',\n",
       "       'depute_sortant', 'ancien_depute', 'au_gouvernement', 'ancien_ministre',\n",
       "       'membre_majorite', 'nb_acces_second_tour', 'nb_candidats_meme_bloc',\n",
       "       'nb_candidats_circo', 'sexe_M'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choix de modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(55.583048394024345, 'score_nuance_groupe_pres'),\n",
       " (14.923681170925649, 'ancien_depute'),\n",
       " (6.3518388017963971, 'membre_majorite'),\n",
       " (5.6728303725751594, 'score_bloc_pres'),\n",
       " (4.4499016785494883, 'nb_acces_second_tour'),\n",
       " (1.0266256449033224, 'nb_candidats_meme_bloc'),\n",
       " (0.8907342190158245, 'depute_sortant'),\n",
       " (0.88603782634228867, 'nb_candidats_circo'),\n",
       " (0.71994412603818159, 'revenus_q1'),\n",
       " (0.7150911750031349, 'revenus_q3'),\n",
       " (0.71406082331041965, 'part_impose'),\n",
       " (0.66764542230964152, 'chom_jeunes'),\n",
       " (0.66674843997368582, 'd_brevet'),\n",
       " (0.56576804536622904, 'd_bac'),\n",
       " (0.52237692332292274, 'revenus_med'),\n",
       " (0.51789181715213084, 'sexe_M'),\n",
       " (0.50518224930232603, 'circo_leg_meme_nuance'),\n",
       " (0.45633801798861562, 'd_bep'),\n",
       " (0.45331423468593202, 'p_commercants'),\n",
       " (0.44755900643814739, 'p_employes'),\n",
       " (0.43480495309438144, 'chom_adultes'),\n",
       " (0.42265417750849121, 'chom_seniors'),\n",
       " (0.41675004566139939, 'p_agri'),\n",
       " (0.40333573038672393, 'd_sup'),\n",
       " (0.39472345184897262, 'chom_tot'),\n",
       " (0.37758547230738554, 'p_ouvriers'),\n",
       " (0.32990267075630841, 'p_intermed'),\n",
       " (0.32180129851011474, 'p_cadres'),\n",
       " (0.086455394269075253, 'au_gouvernement'),\n",
       " (0.065215366480179962, 'circo_pres_meme_nuance'),\n",
       " (0.010153050153108946, 'ancien_ministre')]"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(n_jobs=-1, n_estimators=100)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_val)\n",
    "sorted(list(zip(rf.feature_importances_*100, X_train.columns)), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "clf = XGBRegressor(n_estimators=80, learning_rate=9e-2, max_depth=2)\n",
    "# param_grid = {'n_estimators': [75, 100, 125], #140, 150, 160: 160\n",
    "#               'max_depth' : [2, 3, 5], #70\n",
    "#               'learning_rate' : [0.001, 0.01, 0.1], #0.05, 0.1, 0.2 : 0.05\n",
    "#               'min_child_weight' : [1], #4,5,6 :4\n",
    "#               'reg_alpha' : [0, 1, 2], #8, 10, 12 : 8\n",
    "#               'reg_lambda' : [0, 1, 2] #0.7\n",
    "#              }\n",
    "\n",
    "# rs = RandomizedSearchCV(clf, param_grid, cv=3, n_jobs=-1, verbose=10)\n",
    "# rs.fit(X_train, y_train)\n",
    "# clf = rs.best_estimator_\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred_xgb = clf.predict(X_val)\n",
    "if target_year != 2017:\n",
    "    mean_absolute_error(y_pred_xgb, y_val) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.00342305\n",
      "Validation score: 0.791894\n",
      "Iteration 2, loss = 0.00139441\n",
      "Validation score: 0.829323\n",
      "Iteration 3, loss = 0.00134981\n",
      "Validation score: 0.820424\n",
      "Iteration 4, loss = 0.00131613\n",
      "Validation score: 0.828551\n",
      "Iteration 5, loss = 0.00131537\n",
      "Validation score: 0.831842\n",
      "Iteration 6, loss = 0.00125924\n",
      "Validation score: 0.833783\n",
      "Iteration 7, loss = 0.00127000\n",
      "Validation score: 0.826490\n",
      "Iteration 8, loss = 0.00122499\n",
      "Validation score: 0.837085\n",
      "Iteration 9, loss = 0.00119247\n",
      "Validation score: 0.846304\n",
      "Iteration 10, loss = 0.00122248\n",
      "Validation score: 0.836551\n",
      "Iteration 11, loss = 0.00121233\n",
      "Validation score: 0.839322\n",
      "Iteration 12, loss = 0.00123660\n",
      "Validation score: 0.829586\n",
      "Validation score did not improve more than tol=0.000001 for two consecutive epochs. Stopping.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "reg = MLPRegressor((100, 100, 100), activation='relu', solver='adam', alpha=1e-4, batch_size=200,\n",
    "                   learning_rate='constant', learning_rate_init=5e-3, max_iter=500, tol=1e-6, verbose=True,\n",
    "                  power_t=.5, early_stopping=True)\n",
    "reg.fit(X_train, y_train)\n",
    "y_pred_mlp = reg.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Mix des prédictions des modèles\n",
    "y_pred = np.mean(np.array([y_pred_rf,\n",
    "                           y_pred_mlp,\n",
    "                           y_pred_xgb\n",
    "                          ]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# si 'O' : on note les potentiels qualifiés dès le 1er tour mais on indique aussi le candidat arrivé 2ème\n",
    "# si 'E' : si un candidat est classé 'E', ses concurrents sont automatiquement tous classés 'N'\n",
    "df_predictions = get_classif(y_pred, y_val, df_id, target_values, strategy='O')\n",
    "if target_year!=2017:\n",
    "    analyze_predictions(df_predictions, target_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parti:  1er |  2e | 3e | 4e\n",
      "---------------------------\n",
      "EXG  :    0 |   0 |  0 | 0\n",
      "COM  :    3 |   1 |  0 | 0\n",
      "FI   :    3 |  87 |  0 | 0\n",
      "DVG  :   16 |  12 |  1 | 0\n",
      "ECO  :    5 |   4 |  0 | 0\n",
      "SOC  :   84 |  54 |  0 | 0\n",
      "RDG  :    3 |   2 |  0 | 0\n",
      "MDM  :   37 |  29 |  0 | 0\n",
      "REM  :  248 | 181 |  5 | 0\n",
      "UDI  :   18 |  10 |  0 | 0\n",
      "DVD  :    3 |   7 |  0 | 0\n",
      "LR   :  124 |  96 |  4 | 0\n",
      "DLF  :    1 |   0 |  0 | 0\n",
      "FN   :   18 |  83 | 14 | 0\n",
      "EXD  :    1 |   0 |  0 | 0\n",
      "REG  :    1 |   0 |  0 | 0\n",
      "DIV  :    1 |   0 |  0 | 0\n",
      "[{'Parti': 'FI', '1er': 3, '3e': 0, '2e': 87}, {'Parti': 'SOC', '1er': 84, '3e': 0, '2e': 54}, {'Parti': 'MDM', '1er': 37, '3e': 0, '2e': 29}, {'Parti': 'REM', '1er': 248, '3e': 5, '2e': 181}, {'Parti': 'UDI', '1er': 18, '3e': 0, '2e': 10}, {'Parti': 'LR', '1er': 124, '3e': 4, '2e': 96}, {'Parti': 'DLF', '1er': 1, '3e': 0, '2e': 0}, {'Parti': 'FN', '1er': 18, '3e': 14, '2e': 83}]\n"
     ]
    }
   ],
   "source": [
    "print('Parti:  1er |  2e | 3e | 4e')\n",
    "print('---------------------------')\n",
    "\n",
    "# création JSON pour histogramme et affichage résultats\n",
    "summary = []\n",
    "for parti in ['EXG', 'COM', 'FI', 'DVG', 'ECO', 'SOC', 'RDG', 'MDM', 'REM',\n",
    "              'UDI', 'DVD', 'LR', 'DLF', 'FN', 'EXD', 'REG', 'DIV']:\n",
    "    a = (df_predictions.classement==1) & (df_predictions.nuance == parti)\n",
    "    b = (df_predictions.classement==2) & (df_predictions.qualif == 'O') & (df_predictions.nuance == parti)\n",
    "    c = (df_predictions.classement==3) & (df_predictions.qualif == 'O') & (df_predictions.nuance == parti)\n",
    "    d = (df_predictions.classement==4) & (df_predictions.qualif == 'O') & (df_predictions.nuance == parti)\n",
    "    \n",
    "    print('{:4} :  {:3} | {:3} | {:2} | {:1}'.format(parti, df_predictions[a].shape[0], df_predictions[b].shape[0],\n",
    "                                   df_predictions[c].shape[0], df_predictions[d].shape[0]))\n",
    "    \n",
    "    if parti in ['FI', 'SOC', 'MDM', 'REM', 'UDI', 'LR', 'DLF', 'FN']:\n",
    "        ligne_df = {'Parti': parti, '1er': df_predictions[a].shape[0], '2e': df_predictions[b].shape[0],\n",
    "                   '3e': df_predictions[c].shape[0]}\n",
    "        if df_predictions[d].shape[0]: # cas de quadrangulaire\n",
    "            ligne_df['4e'] = df_predictions[d].shape[0]\n",
    "            \n",
    "        summary.append(ligne_df)\n",
    "    \n",
    "print(summary)\n",
    "df_histo = pd.DataFrame(summary).set_index('Parti')\n",
    "df_histo.to_json('dataviz/data/histogramme_partis_second_tour.json', orient='split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>an</th>\n",
       "      <th>dep</th>\n",
       "      <th>circo</th>\n",
       "      <th>code</th>\n",
       "      <th>nom</th>\n",
       "      <th>prenom</th>\n",
       "      <th>nuance</th>\n",
       "      <th>nuance_groupe</th>\n",
       "      <th>bloc</th>\n",
       "      <th>taux_vote_leg</th>\n",
       "      <th>second_tour</th>\n",
       "      <th>p_exprimes</th>\n",
       "      <th>prediction</th>\n",
       "      <th>classement</th>\n",
       "      <th>qualif</th>\n",
       "      <th>ecart</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5379</th>\n",
       "      <td>2017</td>\n",
       "      <td>PARIS</td>\n",
       "      <td>5</td>\n",
       "      <td>75|5</td>\n",
       "      <td>WELGRYN</td>\n",
       "      <td>LOU</td>\n",
       "      <td>DIV</td>\n",
       "      <td>DIV</td>\n",
       "      <td>Divers</td>\n",
       "      <td>0.5961</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005399</td>\n",
       "      <td>20</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5368</th>\n",
       "      <td>2017</td>\n",
       "      <td>PARIS</td>\n",
       "      <td>5</td>\n",
       "      <td>75|5</td>\n",
       "      <td>EDERICH RIGAUDIERE</td>\n",
       "      <td>CARINE</td>\n",
       "      <td>DIV</td>\n",
       "      <td>DIV</td>\n",
       "      <td>Divers</td>\n",
       "      <td>0.5961</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005399</td>\n",
       "      <td>19</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5323</th>\n",
       "      <td>2017</td>\n",
       "      <td>PARIS</td>\n",
       "      <td>2</td>\n",
       "      <td>75|2</td>\n",
       "      <td>ZANGHELLINI</td>\n",
       "      <td>ANNE</td>\n",
       "      <td>DIV</td>\n",
       "      <td>DIV</td>\n",
       "      <td>Divers</td>\n",
       "      <td>0.6362</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005598</td>\n",
       "      <td>24</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        an    dep  circo  code                 nom  prenom nuance  \\\n",
       "5379  2017  PARIS      5  75|5             WELGRYN     LOU    DIV   \n",
       "5368  2017  PARIS      5  75|5  EDERICH RIGAUDIERE  CARINE    DIV   \n",
       "5323  2017  PARIS      2  75|2         ZANGHELLINI    ANNE    DIV   \n",
       "\n",
       "     nuance_groupe    bloc  taux_vote_leg second_tour  p_exprimes  prediction  \\\n",
       "5379           DIV  Divers         0.5961         NaN         NaN    0.005399   \n",
       "5368           DIV  Divers         0.5961         NaN         NaN    0.005399   \n",
       "5323           DIV  Divers         0.6362         NaN         NaN    0.005598   \n",
       "\n",
       "      classement qualif  ecart  \n",
       "5379          20      N    NaN  \n",
       "5368          19      N    NaN  \n",
       "5323          24      N    NaN  "
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predictions.sort_values(by='prediction').head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>an</th>\n",
       "      <th>dep</th>\n",
       "      <th>circo</th>\n",
       "      <th>code</th>\n",
       "      <th>nom</th>\n",
       "      <th>prenom</th>\n",
       "      <th>nuance</th>\n",
       "      <th>nuance_groupe</th>\n",
       "      <th>bloc</th>\n",
       "      <th>taux_vote_leg</th>\n",
       "      <th>second_tour</th>\n",
       "      <th>p_exprimes</th>\n",
       "      <th>prediction</th>\n",
       "      <th>classement</th>\n",
       "      <th>qualif</th>\n",
       "      <th>ecart</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4259</th>\n",
       "      <td>2017</td>\n",
       "      <td>MAINE-ET-LOIRE</td>\n",
       "      <td>5</td>\n",
       "      <td>49|5</td>\n",
       "      <td>MASSEGLIA</td>\n",
       "      <td>DENIS</td>\n",
       "      <td>REM</td>\n",
       "      <td>REM</td>\n",
       "      <td>Centre</td>\n",
       "      <td>0.5683</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.487124</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7086</th>\n",
       "      <td>2017</td>\n",
       "      <td>VAL-DE-MARNE</td>\n",
       "      <td>7</td>\n",
       "      <td>94|7</td>\n",
       "      <td>BRIDEY</td>\n",
       "      <td>JEAN-JACQUES</td>\n",
       "      <td>REM</td>\n",
       "      <td>REM</td>\n",
       "      <td>Centre</td>\n",
       "      <td>0.5695</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.488532</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3106</th>\n",
       "      <td>2017</td>\n",
       "      <td>HAUTS-DE-SEINE</td>\n",
       "      <td>9</td>\n",
       "      <td>92|9</td>\n",
       "      <td>SOLERE</td>\n",
       "      <td>THIERRY</td>\n",
       "      <td>LR</td>\n",
       "      <td>LR</td>\n",
       "      <td>Droite</td>\n",
       "      <td>0.5916</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.608598</td>\n",
       "      <td>1</td>\n",
       "      <td>E</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        an             dep  circo  code        nom        prenom nuance  \\\n",
       "4259  2017  MAINE-ET-LOIRE      5  49|5  MASSEGLIA         DENIS    REM   \n",
       "7086  2017    VAL-DE-MARNE      7  94|7     BRIDEY  JEAN-JACQUES    REM   \n",
       "3106  2017  HAUTS-DE-SEINE      9  92|9     SOLERE       THIERRY     LR   \n",
       "\n",
       "     nuance_groupe    bloc  taux_vote_leg second_tour  p_exprimes  prediction  \\\n",
       "4259           REM  Centre         0.5683         NaN         NaN    0.487124   \n",
       "7086           REM  Centre         0.5695         NaN         NaN    0.488532   \n",
       "3106            LR  Droite         0.5916         NaN         NaN    0.608598   \n",
       "\n",
       "      classement qualif  ecart  \n",
       "4259           1      O    NaN  \n",
       "7086           1      O    NaN  \n",
       "3106           1      E    NaN  "
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predictions.sort_values(by='prediction').tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "stamp = '{}_{}_{}h{}'.format(now.day, now.month, now.hour, now.minute)\n",
    "\n",
    "# fichier pour simulation second tour\n",
    "liste_id = ['an', 'dep', 'circo', 'code', 'nom', 'prenom', 'nuance', 'bloc']\n",
    "liste_features = ['circo_leg_meme_nuance', 'circo_pres_meme_nuance', 'score_bloc_pres', 'depute_sortant',\n",
    "                  'ancien_depute', 'au_gouvernement', 'ancien_ministre', 'membre_majorite']\n",
    "df_second_tour = pd.concat([df_id[liste_id], X_val[liste_features],\n",
    "                            df_predictions[['prediction', 'qualif']]], axis=1, join='inner')\n",
    "df_predictions.to_excel('data/predictions_du_{}.xlsx'.format(stamp))\n",
    "df_second_tour.to_excel('data/pred_format_second_tour_du_{}.xlsx'.format(stamp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       candidat1            candidat2 candidat3 color1 color2  \\\n",
      "circo                                                                           \n",
      "1-1                Xavier Breton       Laurent Mallet               LR    MDM   \n",
      "1-2    Charles De La Verpilliere  Marie-Jeanne Beguet               LR    MDM   \n",
      "1-3     Stephanie Pernod Beaudon        Olga Givernet               LR    REM   \n",
      "1-4           Stephane Trompille        Guy Billoudet              REM     LR   \n",
      "1-5                  Damien Abad      Helene De Meire               LR    REM   \n",
      "\n",
      "      color3 nom circo    score1    score2 score3  \n",
      "circo                                              \n",
      "1-1            Ain - 1  0.338142  0.272217         \n",
      "1-2            Ain - 2  0.334827  0.265386         \n",
      "1-3            Ain - 3  0.305308  0.282511         \n",
      "1-4            Ain - 4  0.287454  0.261619         \n",
      "1-5            Ain - 5  0.317913  0.240510         \n"
     ]
    }
   ],
   "source": [
    "exportCsv = df_predictions[['dep','circo','code','prenom','nom','nuance','prediction','qualif']]\n",
    "exportCsv['qualif'] = exportCsv['qualif'].apply(lambda x : x.replace('E','O'))\n",
    "exportCsv['code'] = exportCsv['code'].apply(str.lower)\n",
    "exportCsv['code'] = exportCsv['code'].apply(str).apply(lambda x : x.replace('|', '-'))\n",
    "exportCsv['candidat'] = exportCsv['prenom'].apply(str.title) + ' ' + exportCsv['nom'].apply(str.title)\n",
    "exportCsv['nom circo'] = exportCsv['dep'].apply(\n",
    "    lambda x : x.replace('-', ' ')).apply(str.title) + ' - ' + exportCsv['circo'].apply(str)\n",
    "exportCsv = exportCsv.drop(['dep', 'circo', 'prenom', 'nom'], axis=1)\n",
    "exportCsv1 = exportCsv[exportCsv['qualif'] == 'O']\n",
    "exportCsv1 = exportCsv1.drop(['qualif'], axis=1)\n",
    "exportCsv1 = exportCsv1.sort_values(['code', 'prediction'], ascending=[True, False])\n",
    "#print(exportCsv1.head())\n",
    "\n",
    "circos = exportCsv1['code'].unique()\n",
    "temp = pd.DataFrame()\n",
    "d = {}\n",
    "for c in circos:\n",
    "    temp = exportCsv1[exportCsv1['code'] == c]\n",
    "    l = []\n",
    "    for index, rows in temp.iterrows():\n",
    "        l.extend(rows[1:].values)\n",
    "    d[c] = l\n",
    "\n",
    "    \n",
    "duels = {k: v for k, v in d.items() if len(v) < 9}\n",
    "triangulaires = {k: v for k, v in d.items() if len(v) > 9}\n",
    "#quadrangulaires = {k: v for k, v in d.items() if len(v) > 10}\n",
    "\n",
    "duels = pd.DataFrame(duels)\n",
    "duels.index = ['color1','score1','candidat1','nom circo','color2','score2','candidat2','nom circo']\n",
    "duels = duels.T\n",
    "duels = duels.iloc[:,:7]\n",
    "#print(duels.head())\n",
    "\n",
    "triangulaires = pd.DataFrame(triangulaires)\n",
    "triangulaires.index = ['color1','score1','candidat1','nom circo','color2','score2','candidat2','nom circo','color3','score3','candidat3','nom circo']\n",
    "triangulaires = triangulaires.T\n",
    "nomCirco = triangulaires['nom circo'].iloc[:,0]\n",
    "triangulaires = triangulaires.drop('nom circo', axis=1)\n",
    "triangulaires['nom circo'] = nomCirco\n",
    "#print(triangulaires.head())\n",
    "\n",
    "# quadrangulaires = pd.DataFrame(quadrangulaires)\n",
    "# print(quadrangulaires.head())\n",
    "\n",
    "# quadrangulaires.index = ['color1','score1','candidat1','color2','score2','candidat2','color3',\n",
    "#                          'score3','candidat3','color4','score4','candidat4']\n",
    "# quadrangulaires = quadrangulaires.T\n",
    "# print(quadrangulaires.head())\n",
    "\n",
    "# vainqueurs1er.index = vainqueurs1er.code\n",
    "# vainqueurs1er = vainqueurs1er.drop(['code','prenom','nom','qualif'], axis=1)\n",
    "# vainqueurs1er['color1'], vainqueurs1er['score1'], vainqueurs1er['candidat1'] = vainqueurs1er.nuance_groupe,\\\n",
    "# vainqueurs1er.prediction, vainqueurs1er.candidat\n",
    "# vainqueurs1er = vainqueurs1er.drop(['nuance_groupe', 'prediction', 'candidat'], axis=1)\n",
    "# print(vainqueurs1er.head())\n",
    "\n",
    "\n",
    "final = pd.concat([duels, triangulaires])#, quadrangulaires])\n",
    "final = final.fillna(value='')\n",
    "#final = pd.concat([vainqueurs1er, duels, triangulaires])#, quadrangulaires])\n",
    "\n",
    "final.index.name = 'circo'\n",
    "print(final.head())\n",
    "final.to_csv('dataviz/data/resultats1_du_{}.csv'.format(stamp), index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
